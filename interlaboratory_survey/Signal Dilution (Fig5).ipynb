{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65622fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from definitions import ROOT_DIR\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "import re\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns list of hard-coded paths (to avoid repetition in multiple function definitions)\n",
    "def paths():\n",
    "    p_root_dir = Path(ROOT_DIR).parents[0]\n",
    "    p_data = p_root_dir / \"matrix_comparison/5_data_analysis\"\n",
    "    p_out = p_root_dir / \"interlaboratory_survey/6_plots/Interlab\"\n",
    "\n",
    "    # Compounds name and ID information\n",
    "    p_compounds = p_data / \"compounds_ids.csv\"\n",
    "\n",
    "    # Compound mapping to wells\n",
    "    p_wellmap = p_data / \"wellmap.csv\"\n",
    "\n",
    "    # Dataset info (lab, matrix, polarity, m/z range, ids, etc.)\n",
    "    p_datasets = p_data / \"Datasets_14Jul2022.csv\"\n",
    "\n",
    "    # Classification\n",
    "    p_chem_class = p_data / \"custom_classification_v2.csv\"\n",
    "    p_pathways = p_data / \"pathways_v2.csv\"\n",
    "    p_predictions = p_root_dir / \"interlaboratory_survey/5_data_analysis/2022-08-16_All_Interlab_Predictions.csv\"\n",
    "\n",
    "    paths = {\n",
    "            'p_root_dir' : p_root_dir,\n",
    "            'p_data' : p_data,\n",
    "            'p_out' : p_out,\n",
    "            'p_compounds' : p_compounds,\n",
    "            'p_wellmap' : p_wellmap,\n",
    "            'p_datasets' : p_datasets,\n",
    "            'p_chem_class' : p_chem_class,\n",
    "            'p_pathways' : p_pathways,\n",
    "            'p_predictions' : p_predictions\n",
    "    }\n",
    "    return paths\n",
    "\n",
    "#Format ion formulas to publication standard\n",
    "def pretty_ion_formulas(adnl, pol=\"\"):\n",
    "    \n",
    "    adnl = [string.replace(\"[M]-\",\"\") for string in adnl]\n",
    "    adnl = [string.replace(\"[M]+\",\"\") for string in adnl]\n",
    "    adnl = [string.replace(\"++\",\"+\") for string in adnl]\n",
    "    adnl = [string.replace(\"--\",\"-\") for string in adnl]\n",
    "    adnl = [re.sub('([0-9])', '$_\\\\1$', string) for string in adnl]\n",
    "    adnl = ['[M'+string+']' for string in adnl]\n",
    "    if pol == 'Pos':\n",
    "        adnl = [string+'$^+$' for string in adnl]\n",
    "    elif pol == 'Neg':\n",
    "        adnl = [string+'$^-$' for string in adnl]\n",
    "    return adnl\n",
    "\n",
    "#Calculate and store peaks normalized to sum of peaks per molecule\n",
    "def calculate_signal_composition(df):\n",
    "    addlist = []\n",
    "    \n",
    "    for sample in list(set(df['sample_name'])): #For each dataset (one polarity, full range)\n",
    "        \n",
    "        for molecule in list(set(df[df['sample_name']==sample]['name_short'])): #For each unique named molecule\n",
    "            \n",
    "            #Sum up intensities of all matching adduct/neutral loss peaks and store\n",
    "            molsum = sum(df[(df['sample_name']==sample) & (df['name_short']==molecule)]['spot_intensity_bgr_corrected'])\n",
    "            addlist.append({'sample_name':sample, 'name_short':molecule, 'molsum':molsum})\n",
    "    \n",
    "    #Add sum intensity information to main dataframe\n",
    "    addf = pd.DataFrame(addlist)\n",
    "    newdf = pd.merge(df, addf, left_on=['sample_name','name_short'], right_on=['sample_name','name_short'], how='left')\n",
    "    \n",
    "    #Calculate the signal contribution of each row as intensity divided by total intensity\n",
    "    newdf['frac'] = newdf['spot_intensity_bgr_corrected']/newdf['molsum']\n",
    "    return newdf\n",
    "\n",
    "#Load csv files and organize dataframe\n",
    "def prepare_df(paths):\n",
    "\n",
    "    #Load predictions\n",
    "    predictions = pd.read_csv(paths['p_predictions'], index_col=0)\n",
    "    predictions.neutral_loss.fillna('', inplace=True)\n",
    "\n",
    "    #Load metadata files\n",
    "    compounds = pd.read_csv(paths['p_compounds'], index_col='internal_id')\n",
    "    wellmap = pd.read_csv(paths['p_wellmap'], index_col='internal_id')\n",
    "    chem_class = pd.read_csv(paths['p_chem_class'], index_col='internal_id')\n",
    "    pathways = pd.read_csv(paths['p_pathways'], index_col='internal_id')\n",
    "    datasets = pd.read_csv(paths['p_datasets'])\n",
    "    \n",
    "    #Load class data. WARNING: risk of duplication\n",
    "    main_chem_class = chem_class[['name_short', 'main_coarse_class']].drop_duplicates()\n",
    "\n",
    "    # Get a subset of most relevant information from Datasets file and add a unique sample name to each merged dataset (full mass range, single polarity)\n",
    "    datasets_info = datasets.groupby('Dataset ID').first()[['Polarity', 'Participant lab', 'Slide code', 'All', 'EMBL', 'Interlab', 'Technology', 'Matrix short']] # 'Participant lab', 'Technology'\n",
    "    datasets_info['sample_name'] = datasets_info['Slide code'] + ': ' + datasets_info['Technology'] + ': ' + datasets_info['Matrix short']\n",
    "\n",
    "    # Merge with predictions\n",
    "    df = pd.merge(predictions, datasets_info, left_on='dataset_id', right_on='Dataset ID', how='left')\n",
    "    df.sort_values(by = ['adduct', 'neutral_loss'], inplace=True)\n",
    "    \n",
    "    #Format adduct/neutral loss to output-ready format\n",
    "    df['neutral_loss'] = df['neutral_loss'].apply(lambda x: x if len(x) < 7 else '+Matrix')\n",
    "    df['adduct_and_nl'] = pretty_ion_formulas(df.adduct+df.neutral_loss)\n",
    "    df['Polarity'] = [('Pos' if x=='positive' else 'Neg') for x in df['Polarity']] \n",
    "    \n",
    "    #Remove duplicates\n",
    "#    df['problems'] = df['sample_name'] + \"  \" + df['Polarity'] + \", molecule: \" + df['name_short'] + df['adduct_and_nl']\n",
    "#    df.sort_values(by='pred_val', ascending=False)\n",
    "#    df['dupemask']=df.duplicated(subset='problems', keep='first')\n",
    "#    df = df[~df.dupemask].drop(['dupemask','problems'], axis='columns')\n",
    "#    df = df.sort_index()\n",
    "    \n",
    "    #Merge in metadata, apply filters\n",
    "    df = df.merge(main_chem_class, on='name_short', how='left')\n",
    "    df = df[df['Interlab']]\n",
    "    df = df[df['pred_threestate']==2]\n",
    "    df = calculate_signal_composition(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe66b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the main dataframe once (takes a minute or so)\n",
    "df = prepare_df(paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ed97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Signal dilution by class, one plot per technology, 5% threshold5\n",
    "\n",
    "barchart = []\n",
    "\n",
    "# Group data by relevant columns\n",
    "grouped_data = df.groupby(['Polarity', 'adduct_and_nl', 'sample_name', 'name_short', 'Technology', 'main_coarse_class'])\n",
    "\n",
    "# Aggregate composition fraction and intensity\n",
    "agg_data = grouped_data.agg({\n",
    "        'spot_intensity_bgr_corrected' : 'sum',\n",
    "        'frac' : 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "molchart = []        \n",
    "\n",
    "cmap = cm.get_cmap('tab20')\n",
    "colorlist = []\n",
    "\n",
    "#Generate ordered list of all colors in chosen colormap (default tab20)\n",
    "for i in range(cmap.N):\n",
    "    colorlist = colorlist + [matplotlib.colors.rgb2hex(cmap(i))]\n",
    "posnames = []\n",
    "negnames = []\n",
    "\n",
    "for pol in ['Pos', 'Neg']:\n",
    "    \n",
    "    #Generate an ordered list of ions used for coloring bar charts (works because all other plots have a subset of ions found in this)\n",
    "    namelist = []\n",
    "    for tech in set(agg_data['Technology']):\n",
    "    \n",
    "        #Filter out all the good detections in one example dataset\n",
    "        filtered_agg_data = agg_data[(agg_data['Technology'] == tech) & (agg_data['Polarity'] == pol)].reset_index().drop_duplicates()\n",
    "\n",
    "        #Add polarity sign\n",
    "        if pol == 'Pos':\n",
    "            filtered_agg_data['adduct_and_nl'] = [string+'$^+$' for string in filtered_agg_data['adduct_and_nl']]\n",
    "        elif pol == 'Neg':\n",
    "            filtered_agg_data['adduct_and_nl'] = [string+'$^-$' for string in filtered_agg_data['adduct_and_nl']]\n",
    "\n",
    "        result = filtered_agg_data.groupby(['main_coarse_class', 'Polarity', 'adduct_and_nl']).agg({\n",
    "                'spot_intensity_bgr_corrected' : 'sum',\n",
    "                'frac' : 'sum'\n",
    "        }).reset_index()\n",
    "\n",
    "        #Normalize to number of total samples (datasets)\n",
    "        result['frac'] = result['frac'] / len(list(set(filtered_agg_data['sample_name'])))\n",
    "        \n",
    "        #Prepare report\n",
    "        for cclass in set(filtered_agg_data['main_coarse_class']):\n",
    "            rows = result[result['main_coarse_class'] == cclass].sort_values(by='frac', ascending=False)\n",
    "            \n",
    "            #Precalculate sum of all peak intensities contributing at least 10% of total intensity\n",
    "            rowsum = sum(rows['frac'])\n",
    "            threshold = rowsum*0.05\n",
    "            flag = True\n",
    "            sumint = 0\n",
    "\n",
    "            #For each peak sorted in descending order of intensity, \n",
    "            for idx, row in rows.iterrows():\n",
    "                if flag and row.frac < threshold: #Done?\n",
    "                    flag = False\n",
    "                if flag:\n",
    "                    namelist = namelist + [row['adduct_and_nl']]\n",
    "                    \n",
    "    namelist = sorted(list(set(namelist)),key=len)\n",
    "    \n",
    "    #Save for later\n",
    "    if pol == 'Pos':\n",
    "        posnames = namelist\n",
    "    else:\n",
    "        negnames = namelist\n",
    "    \n",
    "    #Save a dictionary of ion names and associated colors\n",
    "    colvals = dict(zip(namelist, colorlist))\n",
    "    \n",
    "    #Generate actual output\n",
    "    for tech in set(agg_data['Technology']):\n",
    "\n",
    "        #Filter out only datasets of the relevant technology and polarity\n",
    "        filtered_agg_data = agg_data[(agg_data['Technology'] == tech) & (agg_data['Polarity'] == pol)].reset_index().drop_duplicates()\n",
    "\n",
    "        #Add polarity sign to formula\n",
    "        if pol == 'Pos':\n",
    "            filtered_agg_data['adduct_and_nl'] = [string+'$^+$' for string in filtered_agg_data['adduct_and_nl']]\n",
    "        elif pol == 'Neg':\n",
    "            filtered_agg_data['adduct_and_nl'] = [string+'$^-$' for string in filtered_agg_data['adduct_and_nl']]\n",
    "        \n",
    "        #Group by relevant columns\n",
    "        result = filtered_agg_data.groupby(['main_coarse_class', 'Polarity', 'adduct_and_nl']).agg({\n",
    "                'spot_intensity_bgr_corrected' : 'sum',\n",
    "                'frac' : 'sum'\n",
    "        }).reset_index()\n",
    "\n",
    "        #Normalize to number of total samples (datasets). This sets the total scale of each bar to exactly 1.\n",
    "        result['frac'] = result['frac'] / len(list(set(filtered_agg_data['sample_name'])))\n",
    "\n",
    "        report = pd.DataFrame()\n",
    "\n",
    "        #Prepare report\n",
    "        for cclass in set(filtered_agg_data['main_coarse_class']):\n",
    "            rows = result[result['main_coarse_class'] == cclass].sort_values(by='frac', ascending=False)\n",
    "            \n",
    "            #Precalculate sum of all peak intensities up to a threshold of total contribution\n",
    "            rowsum = sum(rows['frac'])\n",
    "            threshold = rowsum*0.05\n",
    "            flag = True\n",
    "            sumint = 0\n",
    "\n",
    "            #For each peak sorted in descending order of intensity, \n",
    "            for idx, row in rows.iterrows():\n",
    "                addict  = {'Class':cclass, 'sum':rowsum }\n",
    "                sumint = sumint+row.frac\n",
    "                if flag and row.frac < threshold: #Done?\n",
    "                    addict.update({'adduct_and_nl' : np.nan, #Sum remaining and store as \"nan\"\n",
    "                                    'frac':(rowsum-sumint)/rowsum})\n",
    "                    report = report.append(addict, ignore_index=True)\n",
    "                    flag = False\n",
    "                if flag: #Not done?\n",
    "                    addict.update({'adduct_and_nl' : row['adduct_and_nl'], #Store row\n",
    "                                    'frac':row.frac/rowsum})\n",
    "                    report = report.append(addict, ignore_index=True)\n",
    "\n",
    "        colorfill = scale_fill_manual(values=colvals, na_value='white')\n",
    "\n",
    "        \n",
    "        #Output split barchart\n",
    "        molchart = molchart + [(ggplot(report)\n",
    "        + aes(fill='adduct_and_nl', y='frac', x='Class')  \n",
    "        + geom_bar(position=\"fill\", stat=\"identity\", linetype='solid', color='black')\n",
    "        + coord_flip()\n",
    "        + theme_classic()\n",
    "        + colorfill\n",
    "        + theme(\n",
    "                    aspect_ratio=1,\n",
    "                    text=element_text(family = 'sans-serif', size=16),\n",
    "                    title=element_text(family = 'sans-serif', size=18),\n",
    "                    #legend_position=(0.3, -0.15),\n",
    "                    )\n",
    "        + xlab(\"Class\")\n",
    "        + ylab(\"Fraction of total intensity\")\n",
    "        + labs(fill = \"Adduct + neutral loss\", title = f\"Signal composition ({tech}, {pol})\")\n",
    "        )]\n",
    "\n",
    "save_as_pdf_pages(molchart, paths()['p_out'] / \"Barchart_Dilution_Class_And_Technology_5percent.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Signal dilution by class, one plot per technology, 10% threshold\n",
    "\n",
    "barchart = []\n",
    "\n",
    "# Group data by relevant columns\n",
    "grouped_data = df.groupby(['Polarity', 'adduct_and_nl', 'sample_name', 'name_short', 'Technology', 'main_coarse_class'])\n",
    "\n",
    "# Aggregate composition fraction and intensity\n",
    "agg_data = grouped_data.agg({\n",
    "        'spot_intensity_bgr_corrected' : 'sum',\n",
    "        'frac' : 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "molchart = []        \n",
    "\n",
    "cmap = cm.get_cmap('tab20')\n",
    "colorlist = []\n",
    "\n",
    "#Generate ordered list of all colors in chosen colormap (default tab20)\n",
    "for i in range(cmap.N):\n",
    "    colorlist = colorlist + [matplotlib.colors.rgb2hex(cmap(i))]\n",
    "\n",
    "for pol in ['Pos', 'Neg']:\n",
    "\n",
    "    if pol == 'Pos':\n",
    "        namelist = posnames\n",
    "    else:\n",
    "        namelist = negnames\n",
    "        \n",
    "    #Save a dictionary of ion names and associated colors\n",
    "    colvals = dict(zip(namelist, colorlist))\n",
    "    \n",
    "    #Generate actual output\n",
    "    for tech in set(agg_data['Technology']):\n",
    "\n",
    "        #Filter out only datasets of the relevant technology and polarity\n",
    "        filtered_agg_data = agg_data[(agg_data['Technology'] == tech) & (agg_data['Polarity'] == pol)].reset_index().drop_duplicates()\n",
    "\n",
    "        #Add polarity sign to formula\n",
    "        if pol == 'Pos':\n",
    "            filtered_agg_data['adduct_and_nl'] = [string+'$^+$' for string in filtered_agg_data['adduct_and_nl']]\n",
    "        elif pol == 'Neg':\n",
    "            filtered_agg_data['adduct_and_nl'] = [string+'$^-$' for string in filtered_agg_data['adduct_and_nl']]\n",
    "        \n",
    "        #Group by relevant columns\n",
    "        result = filtered_agg_data.groupby(['main_coarse_class', 'Polarity', 'adduct_and_nl']).agg({\n",
    "                'spot_intensity_bgr_corrected' : 'sum',\n",
    "                'frac' : 'sum'\n",
    "        }).reset_index()\n",
    "\n",
    "        #Normalize to number of total samples (datasets). This sets the total scale of each bar to exactly 1.\n",
    "        result['frac'] = result['frac'] / len(list(set(filtered_agg_data['sample_name'])))\n",
    "\n",
    "        report = pd.DataFrame()\n",
    "\n",
    "        #Prepare report\n",
    "        for cclass in set(filtered_agg_data['main_coarse_class']):\n",
    "            rows = result[result['main_coarse_class'] == cclass].sort_values(by='frac', ascending=False)\n",
    "            \n",
    "            #Precalculate sum of all peak intensities up to a threshold of total contribution\n",
    "            rowsum = sum(rows['frac'])\n",
    "            threshold = rowsum*0.1\n",
    "            flag = True\n",
    "            sumint = 0\n",
    "\n",
    "            #For each peak sorted in descending order of intensity, \n",
    "            for idx, row in rows.iterrows():\n",
    "                addict  = {'Class':cclass, 'sum':rowsum }\n",
    "                sumint = sumint+row.frac\n",
    "                if flag and row.frac < threshold: #Done?\n",
    "                    addict.update({'adduct_and_nl' : np.nan, #Sum remaining and store as \"nan\"\n",
    "                                    'frac':(rowsum-sumint)/rowsum})\n",
    "                    report = report.append(addict, ignore_index=True)\n",
    "                    flag = False\n",
    "                if flag: #Not done?\n",
    "                    addict.update({'adduct_and_nl' : row['adduct_and_nl'], #Store row\n",
    "                                    'frac':row.frac/rowsum})\n",
    "                    report = report.append(addict, ignore_index=True)\n",
    "\n",
    "        colorfill = scale_fill_manual(values=colvals, na_value='white')\n",
    "\n",
    "        \n",
    "        #Output split barchart\n",
    "        molchart = molchart + [(ggplot(report)\n",
    "        + aes(fill='adduct_and_nl', y='frac', x='Class')  \n",
    "        + geom_bar(position=\"fill\", stat=\"identity\", linetype='solid', color='black')\n",
    "        + coord_flip()\n",
    "        + theme_classic()\n",
    "        + colorfill\n",
    "        + theme(\n",
    "                    aspect_ratio=1,\n",
    "                    text=element_text(family = 'sans-serif', size=16),\n",
    "                    title=element_text(family = 'sans-serif', size=18),\n",
    "                    #legend_position=(0.3, -0.15),\n",
    "                    )\n",
    "        + xlab(\"Class\")\n",
    "        + ylab(\"Fraction of total intensity\")\n",
    "        + labs(fill = \"Adduct + neutral loss\", title = f\"Signal composition ({tech}, {pol})\")\n",
    "        )]\n",
    "\n",
    "save_as_pdf_pages(molchart, paths()['p_out'] / \"Barchart_Dilution_Class_And_Technology_10percent.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by compound, dataset and polarity\n",
    "grouped_data = df.groupby(['Polarity', 'adduct_and_nl', 'main_coarse_class'])\n",
    "\n",
    "# Aggregate prediction boolean and intensity\n",
    "agg_data = grouped_data.agg({\n",
    "        'pred_threestate' : 'any',\n",
    "        'frac' : 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "molchart = []\n",
    "\n",
    "cmap = cm.get_cmap('tab20')\n",
    "colorlist = []\n",
    "\n",
    "for i in range(cmap.N):\n",
    "    colorlist = colorlist + [matplotlib.colors.rgb2hex(cmap(i))]\n",
    "\n",
    "\n",
    "\n",
    "for pol in ['Pos', 'Neg']:\n",
    "    \n",
    "\n",
    "    #Filter out all the good detections in one example dataset\n",
    "    filtered_agg_data = agg_data[(agg_data['pred_threestate'] == True) & (agg_data['Polarity'] == pol)].reset_index().drop_duplicates()\n",
    "\n",
    "    if pol == 'Pos':\n",
    "        filtered_agg_data['adduct_and_nl'] = [string+'$^+$' for string in filtered_agg_data['adduct_and_nl']]\n",
    "        polstr = \"Positive\"\n",
    "        colvals = dict(zip(posnames, colorlist))\n",
    "    elif pol == 'Neg':\n",
    "        filtered_agg_data['adduct_and_nl'] = [string+'$^-$' for string in filtered_agg_data['adduct_and_nl']]\n",
    "        polstr = \"Negative\"\n",
    "        colvals = dict(zip(negnames, colorlist))\n",
    "    \n",
    "    result = filtered_agg_data.groupby(['main_coarse_class', 'Polarity', 'adduct_and_nl']).agg({\n",
    "            'frac' : 'sum'\n",
    "\n",
    "    }).reset_index()\n",
    "    \n",
    "    report = pd.DataFrame()\n",
    "\n",
    "    #Prepare report\n",
    "    #for molecule in sorted(set(result['name_short'])):\n",
    "              \n",
    "    \n",
    "    for coarse_class in set(filtered_agg_data['main_coarse_class']):\n",
    "        rows = result[result.main_coarse_class == coarse_class].sort_values(by='frac', ascending=False)\n",
    "        #Precalculate sum of all peak intensities and an 5% threshold level\n",
    "        rowsum = sum(rows['frac'])\n",
    "        threshold = rowsum*0.05\n",
    "        flag = True\n",
    "\n",
    "        sumint = 0\n",
    "\n",
    "        #For each peak sorted in descending order of intensity (far bg normalized), \n",
    "        #save adduct intensity ratio if 80% of max not already reached for molecule\n",
    "        for idx, row in rows.iterrows():\n",
    "            addict  = {'main_coarse_class':coarse_class, 'sum':rowsum }\n",
    "            sumint = sumint+row.frac\n",
    "            \n",
    "            if flag and row.frac < threshold:\n",
    "                addict.update({'adduct_and_nl' : np.nan,\n",
    "                                'frac':(rowsum-sumint)/rowsum})\n",
    "                report = report.append(addict, ignore_index=True)\n",
    "                flag = False\n",
    "            if flag:\n",
    "                addict.update({'adduct_and_nl' : row['adduct_and_nl'],\n",
    "                                'frac':row.frac/rowsum})\n",
    "                report = report.append(addict, ignore_index=True) \n",
    "    \n",
    "    colorfill = scale_fill_manual(values=colvals, na_value='white')\n",
    "              \n",
    "    molchart = molchart + [(ggplot(report)\n",
    "    + aes(fill='adduct_and_nl', y='frac', x='main_coarse_class')  \n",
    "    + geom_bar(position=\"fill\", stat=\"identity\", linetype='solid', color='black')\n",
    "    + coord_flip()\n",
    "    + theme_classic()\n",
    "    + colorfill\n",
    "    + theme(\n",
    "                aspect_ratio=1,\n",
    "                text=element_text(family = 'sans-serif', size=16),\n",
    "                title=element_text(family = 'sans-serif', size=18),\n",
    "                #legend_position=(0.3, -0.15),\n",
    "                )\n",
    "    + xlab(\"Class\")\n",
    "    + ylab(\"Fraction of total intensity\")\n",
    "    + labs(fill = \"Adduct + neutral loss\", title = f\"Signal composition ({pol})\")\n",
    "    )]\n",
    "    \n",
    "save_as_pdf_pages(molchart, paths()['p_out'] / \"Barchart_Coarse_Class_Dilution.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79110c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
