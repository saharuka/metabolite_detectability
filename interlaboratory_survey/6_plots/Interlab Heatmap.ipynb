{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from definitions import ROOT_DIR\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from seriate import seriate\n",
    "from scipy.spatial.distance import pdist\n",
    "from plotnine import *\n",
    "import re\n",
    "\n",
    "rc('font',**{'family':'sans-serif',\n",
    "             'sans-serif':['Arial'],\n",
    "             'size':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ac6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns list of hard-coded paths (to avoid repetition in multiple function definitions)\n",
    "def paths():\n",
    "    p_root_dir = Path(ROOT_DIR).parents[0]\n",
    "    p_data = p_root_dir / \"5_data_analysis\"\n",
    "    p_out = p_root_dir / \"6_plots\" / 'Interlab'\n",
    "\n",
    "    # Compounds name and ID information\n",
    "    p_compounds = p_data / \"compounds_ids.csv\"\n",
    "\n",
    "    # Compound mapping to wells\n",
    "    p_wellmap = p_data / \"wellmap.csv\"\n",
    "\n",
    "    # Dataset info (lab, matrix, polarity, m/z range, ids, etc.)\n",
    "    p_datasets = p_data / \"Datasets_14Jul2022.csv\"\n",
    "\n",
    "    # Classification\n",
    "    p_chem_class = p_data / \"custom_classification_v2.csv\"\n",
    "    p_pathways = p_data / \"pathways_v2.csv\"\n",
    "    p_predictions = p_data / \"2022-08-16_All_Interlab_Predictions.csv\"\n",
    "\n",
    "    paths = {\n",
    "            'p_root_dir' : p_root_dir,\n",
    "            'p_data' : p_data,\n",
    "            'p_out' : p_out,\n",
    "            'p_compounds' : p_compounds,\n",
    "            'p_wellmap' : p_wellmap,\n",
    "            'p_datasets' : p_datasets,\n",
    "            'p_chem_class' : p_chem_class,\n",
    "            'p_pathways' : p_pathways,\n",
    "            'p_predictions' : p_predictions\n",
    "    }\n",
    "    return paths\n",
    "\n",
    "#Format ion formulas to publication standard\n",
    "def pretty_ion_formulas(adnl, pol=\"\"):\n",
    "    \n",
    "    adnl = [string.replace(\"[M]-\",\"\") for string in adnl]\n",
    "    adnl = [string.replace(\"[M]+\",\"\") for string in adnl]\n",
    "    adnl = [string.replace(\"++\",\"+\") for string in adnl]\n",
    "    adnl = [string.replace(\"--\",\"-\") for string in adnl]\n",
    "    adnl = [re.sub('([0-9])', '$_\\\\1$', string) for string in adnl]\n",
    "    adnl = ['[M'+string+']' for string in adnl]\n",
    "    if pol == 'Pos':\n",
    "        adnl = [string+'$^+$' for string in adnl]\n",
    "    elif pol == 'Neg':\n",
    "        adnl = [string+'$^-$' for string in adnl]\n",
    "    return adnl\n",
    "\n",
    "#Calculate and store peaks normalized to sum of peaks per molecule\n",
    "def calculate_signal_composition(df):\n",
    "    addlist = []\n",
    "    \n",
    "    for sample in list(set(df['sample_name'])): #For each dataset (one polarity, full range)\n",
    "        \n",
    "        for molecule in list(set(df[df['sample_name']==sample]['name_short'])): #For each unique named molecule\n",
    "            \n",
    "            #Sum up intensities of all matching adduct/neutral loss peaks and store\n",
    "            molsum = sum(df[(df['sample_name']==sample) & (df['name_short']==molecule)]['spot_intensity_bgr_corrected'])\n",
    "            addlist.append({'sample_name':sample, 'name_short':molecule, 'molsum':molsum})\n",
    "    \n",
    "    #Add sum intensity information to main dataframe\n",
    "    addf = pd.DataFrame(addlist)\n",
    "    newdf = pd.merge(df, addf, left_on=['sample_name','name_short'], right_on=['sample_name','name_short'], how='left')\n",
    "    \n",
    "    #Calculate the signal contribution of each row as intensity divided by total intensity\n",
    "    newdf['frac'] = newdf['spot_intensity_bgr_corrected']/newdf['molsum']\n",
    "    return newdf\n",
    "\n",
    "#Load csv files and organize dataframe\n",
    "def prepare_df(paths):\n",
    "\n",
    "    #Load predictions\n",
    "    predictions = pd.read_csv(paths['p_predictions'], index_col=0)\n",
    "    predictions.neutral_loss.fillna('', inplace=True)\n",
    "\n",
    "    #Load metadata files\n",
    "    compounds = pd.read_csv(paths['p_compounds'], index_col='internal_id')\n",
    "    wellmap = pd.read_csv(paths['p_wellmap'], index_col='internal_id')\n",
    "    chem_class = pd.read_csv(paths['p_chem_class'], index_col='internal_id')\n",
    "    pathways = pd.read_csv(paths['p_pathways'], index_col='internal_id')\n",
    "    datasets = pd.read_csv(paths['p_datasets'])\n",
    "    \n",
    "    #Load class data. WARNING: risk of duplication\n",
    "    main_chem_class = chem_class[['name_short', 'main_coarse_class']].drop_duplicates()\n",
    "\n",
    "    # Get a subset of most relevant information from Datasets file and add a unique sample name to each merged dataset (full mass range, single polarity)\n",
    "    datasets_info = datasets.groupby('Dataset ID').first()[['Polarity', 'Participant lab', 'Slide code', 'All', 'EMBL', 'Interlab', 'Technology', 'Matrix short']] # 'Participant lab', 'Technology'\n",
    "    datasets_info['sample_name'] = datasets_info['Slide code'] + ': ' + datasets_info['Technology'] + ': ' + datasets_info['Matrix short']\n",
    "\n",
    "    # Merge with predictions\n",
    "    df = pd.merge(predictions, datasets_info, left_on='dataset_id', right_on='Dataset ID', how='left')\n",
    "    df.sort_values(by = ['adduct', 'neutral_loss'], inplace=True)\n",
    "    \n",
    "    #Format adduct/neutral loss to output-ready format\n",
    "    df['neutral_loss'] = df['neutral_loss'].apply(lambda x: x if len(x) < 7 else '+Matrix')\n",
    "    df['adduct_and_nl'] = pretty_ion_formulas(df.adduct+df.neutral_loss)\n",
    "    try:\n",
    "        df['Polarity'] = [('Pos' if x=='positive' else 'Neg') for x in df['Polarity']] \n",
    "    except:\n",
    "        print(df.columns)\n",
    "    \n",
    "    #Merge in metadata, apply filters\n",
    "    df = df.merge(main_chem_class, on='name_short', how='left')\n",
    "    df = df[df['Interlab']]\n",
    "    df = df[df['pred_threestate']==2]\n",
    "    df = calculate_signal_composition(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5614d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = prepare_df(paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-religious",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_neutral_losses(df, filter_on=True, neutral_losses_to_keep=['']):\n",
    "    '''\n",
    "    Filter out entries for ions with neutral losses that are not in the list provided\n",
    "    '''\n",
    "    if filter_on==True:\n",
    "        df = df[df.neutral_loss.isin(neutral_losses_to_keep)]\n",
    "    elif filter_on == 'only_nl':\n",
    "        df = df[df.neutral_loss != '']\n",
    "    return df\n",
    "\n",
    "def calculate_detected_intensities(df):\n",
    "    '''\n",
    "    Make a column with background corrected intensities for detected compounds, and 0s for not detected compounds\n",
    "    Change any negative values to zero\n",
    "    '''\n",
    "    intensities_for_twostate_spots = (df.pred_twostate == 1) * df.spot_intensity_bgr_corrected\n",
    "    df['val_twostate'] = np.clip(intensities_for_twostate_spots, 0, None)\n",
    "    intensities_for_threestate_spots = (df.pred_threestate == 2) * df.spot_intensity_bgr_corrected\n",
    "    df['val_threestate'] = np.clip(intensities_for_threestate_spots, 0, None)\n",
    "    return df\n",
    "\n",
    "def filter_polarity(df, polarity):\n",
    "    '''\n",
    "    Filter out entries based on polarity pol ['pos', 'neg']\n",
    "    '''\n",
    "    return df[df['Polarity'] == polarity]\n",
    "\n",
    "def group_by_molecule(df, intensity_col_name, prediction_col_name):\n",
    "    '''\n",
    "    Aggregate intensity and detection values per class\n",
    "    '''\n",
    "    \n",
    "    if intensity_col_name == 'val_threestate':\n",
    "        intensity_aggregation_func = lambda x: (x==2).any()\n",
    "    else: intensity_aggregation_func = lambda x: (x==1).any()\n",
    "            \n",
    "    \n",
    "    data = df.pivot_table(index=['name_short'],\n",
    "                          columns=['sample_name'],\n",
    "                          values=[intensity_col_name, prediction_col_name],\n",
    "                          aggfunc = {\n",
    "                                intensity_col_name : lambda x: np.log10(sum(x)+1),\n",
    "                                prediction_col_name : intensity_aggregation_func\n",
    "                          },\n",
    "                          fill_value=0,)\n",
    "    data = data.stack(level=1, dropna=False).reset_index()\n",
    "    # If no ions on a molecule were detected by matrix, prediction column contains fill value 0 instead of False, correct for that:\n",
    "    data.at[data[prediction_col_name] == 0, prediction_col_name] = False\n",
    "    return data\n",
    "\n",
    "def prep_molecule_data(data, polarity,  intensity_col_name, prediction_col_name, nl_filter_on=False, neutral_losses_to_keep=None):\n",
    "    '''\n",
    "    '''\n",
    "    data = filter_neutral_losses(data, nl_filter_on, neutral_losses_to_keep)\n",
    "    data = calculate_detected_intensities(data)\n",
    "    data = filter_polarity(data, polarity)\n",
    "    data = group_by_molecule(data, intensity_col_name, prediction_col_name)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def summarise_per_fine_class(df, fine_class_col_name, coarse_class_col_name, intensity_col_name, prediction_col_name):\n",
    "    \n",
    "    df['class_size'] =1\n",
    "    data = df.pivot_table(index=['sample_name'],\n",
    "                                   columns=[fine_class_col_name, coarse_class_col_name],\n",
    "                                   values=[intensity_col_name, prediction_col_name, 'class_size'],\n",
    "                                   aggfunc = {\n",
    "                                        'class_size':sum,\n",
    "                                        prediction_col_name : sum,\n",
    "                                        intensity_col_name : np.mean\n",
    "                                   },\n",
    "                                   fill_value=0)\n",
    "    \n",
    "    data = data.stack(level=[1,2], dropna=True).reset_index()\n",
    "    data['fraction_detected'] = data[prediction_col_name] / data['class_size']    \n",
    "    \n",
    "    # sort columns alphabetically\n",
    "    data = data.sort_values(by='sample_name')\n",
    "    # sort rows first by coarse class, then by fine class\n",
    "    data = data.sort_values(by=[coarse_class_col_name, fine_class_col_name])\n",
    "    return data\n",
    "\n",
    "def summarise_per_coarse_class(df, class_col_name, intensity_col_name, prediction_col_name):\n",
    "    \n",
    "    df['class_size'] = 1\n",
    "    data = df.pivot_table(index=['sample_name'],\n",
    "                                   columns=class_col_name,\n",
    "                                   values=[intensity_col_name, prediction_col_name, 'class_size'],\n",
    "                                   aggfunc = {\n",
    "                                        'class_size':sum,\n",
    "                                        prediction_col_name : sum,\n",
    "                                        intensity_col_name : np.mean\n",
    "                                   },\n",
    "                                   fill_value=0)\n",
    "    \n",
    "    data = data.stack(level=1, dropna=False).reset_index()\n",
    "    data['fraction_detected'] = data[prediction_col_name] / data['class_size']\n",
    "    \n",
    "    \n",
    "    # sort columns alphabetically\n",
    "    data = data.sort_values(by='sample_name')    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pol in ['Pos', 'Neg']:\n",
    "    molecule_data = prep_molecule_data(df,\n",
    "                                       polarity=pol, \n",
    "                                       nl_filter_on=True, \n",
    "                                       neutral_losses_to_keep=[''], \n",
    "                                       intensity_col_name= 'val_threestate',\n",
    "                                       prediction_col_name = 'pred_threestate')\n",
    "\n",
    "    # Map chemical classes\n",
    "    chem_class = pd.read_csv(paths()['p_chem_class'], index_col='internal_id')\n",
    "    mapped_data = molecule_data.merge(chem_class, on='name_short', how='left')\n",
    "\n",
    "    class_data = summarise_per_coarse_class(mapped_data,\n",
    "                                                class_col_name='main_coarse_class',\n",
    "                                                intensity_col_name= 'val_threestate',\n",
    "                                                prediction_col_name = 'pred_threestate')\n",
    "\n",
    "\n",
    "    plot_data = class_data.pivot_table(index = ['sample_name'],\n",
    "                                           columns=['main_coarse_class'],\n",
    "                                           values=['fraction_detected'],\n",
    "                                           aggfunc = {\n",
    "                                                'fraction_detected':sum,\n",
    "                                           },\n",
    "                                           fill_value=0).T\n",
    "    plot_data = plot_data.reindex(columns=plot_data.columns[seriate(pdist(plot_data.T.to_numpy()))])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "\n",
    "    g = sns.heatmap(data=plot_data, \n",
    "                    yticklabels=plot_data.index.get_level_values(1), \n",
    "                    cmap='viridis',\n",
    "                    cbar_kws={'label': 'Fraction Detected'}\n",
    "                   )\n",
    "\n",
    "    #plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "    plt.title(f\"{pol}\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    #plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    g.figure.savefig(paths()['p_out'] / f\"Heatmap_{pol}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12dc21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
