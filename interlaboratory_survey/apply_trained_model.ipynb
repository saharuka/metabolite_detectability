{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:33.610129Z",
     "start_time": "2021-06-02T16:06:33.498927Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.264180Z",
     "start_time": "2021-06-02T16:06:33.940237Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.ndimage import binary_dilation\n",
    "from sklearn import clone\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from definitions import ROOT_DIR\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from metaspace.sm_annotation_utils import SMInstance\n",
    "from metaspace.image_processing import clip_hotspots\n",
    "\n",
    "import getpass\n",
    "from metaspace import SMInstance\n",
    "from datetime import datetime\n",
    "\n",
    "from matplotlib.colors import Normalize, LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.285960Z",
     "start_time": "2021-06-02T16:06:34.265231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings, because many models spam them during feature selection\n",
    "# as some subsets of features just don't have enough information to make\n",
    "# a good model.\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.833722Z",
     "start_time": "2021-06-02T16:06:34.810682Z"
    }
   },
   "outputs": [],
   "source": [
    "def colorize_image_with_mask(image, mask):\n",
    "    \"\"\"Plotting function for combining a colorized ion image with a spot mask\"\"\"\n",
    "    \n",
    "    image = clip_hotspots(image)\n",
    "    image /= np.max(image)\n",
    "    \n",
    "    on_spot_colorized = plt.cm.cividis(image)\n",
    "    off_spot_colorized = plt.cm.magma(image)\n",
    "    return np.where(mask[:,:,np.newaxis], on_spot_colorized, off_spot_colorized)\n",
    "    \n",
    "def save_image_with_mask(image, mask, fname):\n",
    "    plt.imsave(fname, colorize_image_with_mask(image, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:35.191813Z",
     "start_time": "2021-06-02T16:06:35.170946Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_zeros(img):\n",
    "    \"\"\"Crop an image, removing all empty outer rows/columns\"\"\"\n",
    "    cols = np.flatnonzero(np.count_nonzero(img, axis=0) != 0)\n",
    "    rows = np.flatnonzero(np.count_nonzero(img, axis=1) != 0)\n",
    "    top = rows[0]\n",
    "    bottom = rows[-1] + 1\n",
    "    left = cols[0]\n",
    "    right = cols[-1] + 1\n",
    "\n",
    "    return img[top:bottom, left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:35.605701Z",
     "start_time": "2021-06-02T16:06:35.584102Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mispredictions(model, X, y):\n",
    "    \"\"\"\n",
    "    Find which values would be mispredicted, returning two lists:\n",
    "        * indexes of items that would be falsely predicted as positives\n",
    "        * indexes of items that would be falsely predicted as negatives\n",
    "        \n",
    "    cross_val_predict uses a shuffled 5-fold test-train split so that each chunk of \n",
    "    20% of the input data gets its own model that was trained on the other 80%, \n",
    "    ensuring that the items being predicted aren't included in the training data.\n",
    "    \"\"\"\n",
    "    preds = cross_val_predict(model, X, y)\n",
    "    mispreds = preds != y\n",
    "    fpos_idxs = np.flatnonzero(mispreds & ~y)\n",
    "    fneg_idxs = np.flatnonzero(mispreds & y)\n",
    "        \n",
    "    return fpos_idxs, fneg_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:36.849373Z",
     "start_time": "2021-06-02T16:06:36.826914Z"
    }
   },
   "outputs": [],
   "source": [
    "p_root_dir = Path(ROOT_DIR)\n",
    "p_proj_root_dir = p_root_dir.parents[0]\n",
    "p_matrix_root_dir = p_proj_root_dir / \"matrix_comparison\"\n",
    "p_matrix_data = p_matrix_root_dir / \"5_data_analysis\"\n",
    "\n",
    "p_data = p_root_dir / \"5_data_analysis\"\n",
    "p_analysis = p_root_dir  / \"4_model_evaluation\"\n",
    "p_grids = p_root_dir / r\"2_grid_calibration/grid_masks/20labs_all\"\n",
    "p_wellmap = p_matrix_data / \"wellmap.csv\"\n",
    "\n",
    "# Paths for evaluation\n",
    "p_eval = p_analysis / \"model_application\"\n",
    "p_pickles = p_eval / \"pickles\"\n",
    "p_metrics = p_eval / \"metrics\"\n",
    "p_apply = p_analysis / \"model_application_best_replicates\"\n",
    "p_images = p_eval / \"images.hdf5\"\n",
    "p_model = p_matrix_root_dir / \"3_model_evaluation\\model_evaluation\\model.json\"\n",
    "p_datasets = p_root_dir / \"5_data_analysis/Datasets_modified.csv\"\n",
    "p_metadata = p_matrix_data / \"Datasets_14Jul2022.csv\"\n",
    "p_chem_class = p_matrix_data / \"custom_classification_v2.csv\"\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%d-%b-%Y\") \n",
    "p_predictions = p_eval / f\"all_predictions_{timestamp}.csv\"\n",
    "p_predictions_curated = p_apply / f\"all_predictions_curated_{timestamp}.csv\"\n",
    "\n",
    "# False positives/negatives - preview output from model prediction for molecules with known labels\n",
    "# Note that all files in these directories are cleared before a prediction run\n",
    "p_eval_fpos = p_eval / 'false_positives'\n",
    "p_eval_fneg = p_eval / 'false_negatives'\n",
    "p_eval_tpos = p_eval / 'true_positives'\n",
    "p_eval_tneg = p_eval / 'true_negatives'\n",
    "# Unknown positives/negatives - preview output from model prediction for molecules with no label\n",
    "# Note that all files in these directories are cleared before a prediction run\n",
    "p_eval_upos = p_eval / 'unknown_positives'\n",
    "p_eval_uneg = p_eval / 'unknown_negatives'\n",
    "# Manually labeled positives/negatives - Move preview files from any of the above directories into \n",
    "# these directories to add to the labelled data. Make sure to re-run the appropriate steps \n",
    "# in \"Input data\" to detect the changes\n",
    "p_eval_lpos = p_eval / 'manual_label_positives'\n",
    "p_eval_lneg = p_eval / 'manual_label_negatives'\n",
    "# Manually labeled positives/negatives - Move preview files from any of the above directories into \n",
    "# these directories to add to the labelled data. Make sure to re-run the appropriate steps \n",
    "# in \"Input data\" to detect the changes\n",
    "p_apply_lpos = p_apply / 'manual_label_positives'\n",
    "p_apply_lneg = p_apply / 'manual_label_negatives'\n",
    "# Directories for three-state positive/unsure/negative classification\n",
    "p_tri_pos = p_eval / 'three-state' / 'positive'\n",
    "p_tri_unk = p_eval / 'three-state' / 'unsure'\n",
    "p_tri_neg = p_eval / 'three-state' / 'negative'\n",
    "\n",
    "# METASPACE\n",
    "database = ('Spotting_project_compounds-v9', 'feb2021')\n",
    "fdr = 0.5\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into metaspace\n",
    "sm = SMInstance(host='https://metaspace2020.eu')\n",
    "\n",
    "if not sm.logged_in():\n",
    "    # Using getpass here prevents the API key from being accidentally saved with this notebook.\n",
    "    api_key = getpass.getpass(prompt='API key: ', stream=None)\n",
    "    sm.login(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:38.160316Z",
     "start_time": "2021-06-02T16:06:38.112047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dataset IDs based on grid files \n",
    "datasets = pd.read_csv(p_datasets)\n",
    "dataset_stems = [x.stem[-20:] for x in p_grids.glob(\"*.npy\")]\n",
    "dataset_paths = [x for x in p_grids.glob(\"*.npy\")]\n",
    "dataset_names = [x.stem for x in p_grids.glob(\"*.npy\")]\n",
    "dataset_ids = datasets['Clone ID']\n",
    "dataset_new_ids = datasets['20 Labs ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if we need to download additional data (assumes that correctly named pickle files are correct!)\n",
    "to_download = []\n",
    "pickles = [x.stem[-20:] for x in p_pickles.glob(\"*.pkl\")]\n",
    "for i, ds_id in enumerate(dataset_new_ids):\n",
    "    if ds_id not in pickles:\n",
    "        print(ds_id)\n",
    "        to_download.append(ds_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:08:50.018554Z",
     "start_time": "2021-06-02T16:06:38.808059Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Images from METASPACE\n",
    "# Ignore any warnings about connection pools in this step\n",
    "\n",
    "p_eval.mkdir(parents=True, exist_ok=True)\n",
    "#pickles = [x.stem[-20:] for x in p_eval.glob(\"*.pkl\")]\n",
    "\n",
    "# images = []\n",
    "for i, ds_id in enumerate(dataset_new_ids):\n",
    "    if ds_id in to_download:\n",
    "        images = []\n",
    "        print(f'Downloading images for {ds_id} ({i}/{len(dataset_ids)-1})')\n",
    "        dataset = sm.dataset(id=ds_id)\n",
    "        ds_tic_image = dataset.tic_image()\n",
    "        for img in dataset.all_annotation_images(\n",
    "            fdr=fdr, \n",
    "            database=database, \n",
    "            only_first_isotope=True, \n",
    "            scale_intensity=True, \n",
    "            hotspot_clipping=False\n",
    "        ):\n",
    "            # Exclude annotations with no first-isotopic-image\n",
    "            if img[0] is not None:\n",
    "                images.append({\n",
    "                    'dataset_id': ds_id,\n",
    "                    'formula': img.formula,\n",
    "                    'adduct': img.adduct,\n",
    "                    'neutral_loss': img.neutral_loss or '',\n",
    "                    'image': img[0],\n",
    "                    'tic_norm_image': np.nan_to_num(img[0] / ds_tic_image),  # nan_to_num replaces nan values with 0.0. This line will probably complain about division by zero but it can be ignored as it's fixed by the nan_to_num\n",
    "                })\n",
    "        images_df = pd.DataFrame(images)\n",
    "        images_df.to_pickle(p_pickles / f\"images_{ds_id}.pkl\")\n",
    "        print(f'Images for {ds_id} saved')\n",
    "    # del images; images = []\n",
    "            \n",
    "# images_df = pd.DataFrame(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:00.872379Z",
     "start_time": "2021-06-02T16:09:00.846905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wellmap and grids\n",
    "wellmap = pd.read_csv(p_wellmap)\n",
    "grids = {\n",
    "    ds_stem: np.load(ds_p) \n",
    "    for ds_stem, ds_p in zip(dataset_stems, dataset_paths)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check - do we have all the data that we have grids for?\n",
    "sorted(set(grids)) == sorted(set(dataset_stems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics (or load pre-calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "def calc_far_bg(mask, bg):\n",
    "    \"\"\"Gets mask for background pixels that are at least 4 radii away from the spot\"\"\"\n",
    "    # 3 iterations = (1+3=)4x the spot radius\n",
    "    expanded_spot = binary_dilation(mask, crop_zeros(mask), iterations=3)\n",
    "    return bg & ~expanded_spot\n",
    "\n",
    "def occ(px):\n",
    "    \"\"\"Calculates non-zero % of the given array\"\"\"\n",
    "    return np.count_nonzero(px) / px.size\n",
    "\n",
    "def calculate_metrics(merged_df, grids, dataset_ids, dataset_new_ids, path):\n",
    "    \n",
    "    lasterror = \"\"\n",
    "    progress = 0\n",
    "    metrics = []\n",
    "    \n",
    "    for row in merged_df.itertuples():\n",
    "        \n",
    "        progress = progress+1\n",
    "        if progress % 1000 == 0:\n",
    "            print(progress)\n",
    "        \n",
    "        if row.dataset_id in list(dataset_new_ids):\n",
    "            oid = list(dataset_ids[dataset_new_ids==row.dataset_id].values)[0]\n",
    "            grid = grids[oid]\n",
    "        else:\n",
    "            grid= grids[row.dataset_id]\n",
    "\n",
    "        mask = grid == row.well\n",
    "        bg = grid == 0\n",
    "        \n",
    "        #Catch missing wells\n",
    "        try:\n",
    "            far_bg = calc_far_bg(mask, bg)\n",
    "        except:\n",
    "            error = f\"Missing well: {row.dataset_id} #{row.well}\"\n",
    "            if error != lasterror:\n",
    "                print(error)\n",
    "                lasterror = error\n",
    "            continue\n",
    "\n",
    "        in_mask = row.image[mask]   \n",
    "        in_bg = row.image[bg]\n",
    "        in_far_bg = row.image[far_bg]   \n",
    "        in_other_spots = row.image[~bg & ~mask]\n",
    "\n",
    "        # tic image\n",
    "        in_mask_tic_norm = row.tic_norm_image[mask]\n",
    "        in_bg_tic_norm = row.tic_norm_image[bg]\n",
    "        in_far_bg_tic_norm = row.tic_norm_image[far_bg]\n",
    "        in_other_spots_tic_norm = row.tic_norm_image[~bg & ~mask]\n",
    "\n",
    "        # Calculate threshold (0.01 * 99th percentile) \n",
    "        # (note the image is already hotspot-removed, so the max is the 99th percentile)\n",
    "        threshold = np.max(row.image) * 0.01\n",
    "        metrics.append({\n",
    "            'row_id': row[0],   # with .itertuples(), item[0] is the index\n",
    "            'dataset_id' : row.dataset_id,\n",
    "            'name_short' : row.name_short,\n",
    "            'formula' : row.formula,\n",
    "            'adduct' : row.adduct,\n",
    "            'neutral_loss' : row.neutral_loss,\n",
    "            'well' : row.well,\n",
    "            # Original metrics\n",
    "            # NOTE: The constant in the denominator of `on_off_ratio` was changed to\n",
    "            # 0.001 as it seemed to produce slightly better results\n",
    "            'occupancy_ratio': (occ(in_mask) * 100) / (occ(in_bg) * 100 + 1),\n",
    "            'on_off_ratio': (np.mean(in_mask)) / (np.mean(in_bg) + 0.001),\n",
    "\n",
    "            # Single-spot occupancy %\n",
    "            'spot_occupancy': occ(in_mask),\n",
    "            'spot_occupancy_thresholded': occ(in_mask > threshold),\n",
    "            # Other occupancy metrics\n",
    "            'image_occupancy': occ(row.image),\n",
    "            'other_spots_occupancy': occ(in_other_spots),\n",
    "            'bg_occupancy': occ(in_bg),\n",
    "            'far_bg_occupancy': occ(in_bg),\n",
    "            'occupancy_vs_far_bg_ratio' : (occ(in_mask) * 100) / (occ(in_far_bg) * 100 + 1),\n",
    "\n",
    "            # How many spots have a non-zero pixel\n",
    "            'in_n_spots': len(np.unique(grid[(grid != 0) & (row.image > threshold)])),\n",
    "\n",
    "            # Intensity ratios\n",
    "            'spot_intensity' : np.mean(in_mask),\n",
    "            'spot_intensity_bgr_corrected' : np.mean(in_mask) - np.mean(in_far_bg),\n",
    "            'spot_intensity_sum' : np.sum(in_mask),\n",
    "            'spot_intensity_std' : np.std(in_mask),\n",
    "            'other_spot_intensity': np.mean(in_other_spots),\n",
    "            'bg_intensity' : np.mean(in_bg),\n",
    "            'far_bg_intensity' : np.mean(in_far_bg),\n",
    "            'intensity_vs_far_bg_ratio': np.mean(in_mask) / (np.mean(in_far_bg) + 0.001),\n",
    "            'intensity_vs_other_spots_ratio': np.mean(in_mask) / (np.mean(in_other_spots) + 0.001),\n",
    "           \n",
    "            # Intensity ratios for TIC normalised\n",
    "            'spot_intensity_tic_norm': np.mean(in_mask_tic_norm),\n",
    "            'spot_intensity_bgr_corrected_tic_norm' : np.mean(in_mask_tic_norm) - np.mean(in_far_bg_tic_norm),\n",
    "            'spot_intensity_sum_tic_norm' : np.sum(in_mask_tic_norm),\n",
    "            'spot_intensity_std_tic_norm' : np.std(in_mask_tic_norm),\n",
    "            'other_spot_intensity_tic_norm': np.mean(in_other_spots_tic_norm),\n",
    "            'bg_intensity_tic' : np.mean(in_bg_tic_norm),\n",
    "            'far_bg_intensity_tic' : np.mean(in_far_bg_tic_norm),\n",
    "            'intensity_vs_far_bg_ratio_tic': np.mean(in_mask_tic_norm) / (np.mean(in_far_bg_tic_norm) + 0.001),\n",
    "            'intensity_vs_other_spots_ratio_tic': np.mean(in_mask_tic_norm) / (np.mean(in_other_spots_tic_norm) + 0.001),\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics).set_index('row_id')\n",
    "    metrics_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-saved individual images_df and generate metrics\n",
    "start = 0 #Start and end points allow running a subset of pickles (for example when adding more data to the project)\n",
    "count = 0\n",
    "end = 200\n",
    "for fpath in p_eval.rglob(\"*.pkl\"):\n",
    "    if fpath.stem[-20:] in pickles and count >= start and count <= end:\n",
    "        print(f\"Loading {fpath.name}\")\n",
    "        try:\n",
    "            f = pd.read_pickle(fpath)\n",
    "        except:\n",
    "            print(f\"Failed to load {fpath.name}\")\n",
    "            continue\n",
    "        merged_df = f.merge(wellmap[['well', 'formula', 'name_short']], on=['formula']).reset_index()\n",
    "        merged_df['row_id'] = [f'{row.dataset_id}_{row.formula}_{row.adduct}_{row.neutral_loss}_{row.well}' for row in merged_df.itertuples()]\n",
    "        merged_df = merged_df.set_index('row_id')\n",
    "        print(merged_df['dataset_id'].unique())\n",
    "        calculate_metrics(merged_df, grids, dataset_ids, dataset_new_ids, p_metrics / f\"Metrics_{timestamp}_{count}.csv\")\n",
    "            \n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple metrics files and join\n",
    "metrics_list = []\n",
    "for fpath in p_metrics.rglob(\"*.csv\"):\n",
    "    #if fpath.stem[-20:] in list(dataset_new_ids):\n",
    "    #print(f\"Loading {fpath.name}\")\n",
    "    try:\n",
    "        f = pd.read_csv(fpath, index_col=0)\n",
    "        metrics_list.append(f)\n",
    "    except:\n",
    "        print(f\"Failed to load {fpath.name}\")\n",
    "metrics_df = pd.concat(metrics_list)#.reset_index()\n",
    "# metrics_df = metrics_df.set_index('row_id')\n",
    "# metrics_df = metrics_df.drop(columns=['index'])\n",
    "metrics_df['score'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results for a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T15:54:16.477074Z",
     "start_time": "2021-06-02T15:53:05.276Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(verbose=False)\n",
    "features = ['spot_intensity_tic_norm', 'spot_occupancy', 'occupancy_vs_far_bg_ratio', 'intensity_vs_far_bg_ratio', 'intensity_vs_other_spots_ratio']\n",
    "\n",
    "model.load_model(p_model, format='json')\n",
    "\n",
    "# Make predictions for all data\n",
    "predictions_df = pd.DataFrame({\n",
    "    'pred_val': model.predict_proba(metrics_df[features].values)[:, 1]\n",
    "}, index=metrics_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both options: Assign labels to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:47.130742Z",
     "start_time": "2021-06-02T16:58:47.104805Z"
    }
   },
   "outputs": [],
   "source": [
    " # Make combined DF\n",
    "output_df = metrics_df.join(predictions_df)\n",
    "output_df = output_df[output_df['pred_val'] > -1] #Drops nan\n",
    "#output_df = metrics_df.join(predictions_df)\n",
    "\n",
    "# Add two-state and three-state classes\n",
    "output_df['pred_twostate'] = np.where(output_df.pred_val < 0.5, 0, 1)\n",
    "unsure_range = [0.2, 0.8] # Lowest & highest values to include in the \"unsure\" class\n",
    "# This assigns 0 = negative, 1 = unsure, 2 = positive\n",
    "output_df['pred_threestate'] = np.digitize(output_df.pred_val, unsure_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write predictions CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually merging results from partially overlapping images. \n",
    "#Simple way by reassigning all ids to the primary image, then removing any duplicates (from the overlap)\n",
    "\n",
    "csv_df = output_df\n",
    "csv_df = csv_df.replace('2022-02-18_23h32m33s','2022-02-18_23h32m31s')\n",
    "csv_df = csv_df.replace('2022-02-18_23h32m37s','2022-02-18_23h32m35s')\n",
    "csv_df = csv_df.replace('2022-02-18_23h32m46s','2022-02-18_23h32m44s')\n",
    "\n",
    "csv_df = csv_df.drop_duplicates(subset=['dataset_id','well','formula','adduct','neutral_loss'])\n",
    "\n",
    "#Trim overlapping annotations in unmerged dataset pairs, keep highest pred_val\n",
    "\n",
    "datasets = pd.read_csv(p_metadata)\n",
    "datasets_info = datasets.groupby('Dataset ID').first()[['Polarity', 'Participant lab', 'Slide code', 'All', 'EMBL', 'Interlab', 'Technology', 'Matrix short']] # 'Participant lab', 'Technology'\n",
    "datasets_info['sample_name'] = datasets_info['Slide code'] + ': ' + datasets_info['Technology'] + ': ' + datasets_info['Matrix short']\n",
    "df = pd.merge(csv_df, datasets_info[['sample_name', 'Polarity']], left_on='dataset_id', right_on='Dataset ID', how='left')\n",
    "df.sort_values(by='pred_val', ascending=False)\n",
    "df = df.drop_duplicates(subset=['sample_name','well','formula','adduct','neutral_loss', 'Polarity'], keep='first')\n",
    "df = df.drop(columns=['sample_name', 'Polarity']).sort_index()\n",
    "\n",
    "csv_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:48.369446Z",
     "start_time": "2021-06-02T16:58:48.294036Z"
    }
   },
   "outputs": [],
   "source": [
    "#csv_df = output_df.drop(columns=['image', 'filename']) # Skip unwanted columns\n",
    "csv_df.to_csv(p_predictions)\n",
    "\n",
    "for dataset_id, results_df in csv_df.groupby('dataset_id'):\n",
    "    output_path = p_eval / f'{dataset_id}_predictions.csv'\n",
    "    results_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write image files into false positives, false negatives, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-02T16:58:53.453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean output directories\n",
    "for output_path in [\n",
    "#     p_eval_fpos, p_eval_fneg, p_eval_tpos, p_eval_tneg, \n",
    "    p_eval_upos, p_eval_uneg, \n",
    "    p_tri_pos, p_tri_unk, p_tri_neg\n",
    "]:\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    for f in output_path.glob('*.png'):\n",
    "        f.unlink()  # Delete existing files\n",
    "\n",
    "# Write images with two-state classification\n",
    "for row in output_df.itertuples():\n",
    "    \n",
    "    if row.dataset_id in list(dataset_new_ids):\n",
    "        oid = list(dataset_ids[dataset_new_ids==row.dataset_id].values)[0]\n",
    "        grid = grids[oid]\n",
    "    else:\n",
    "        grid = grids[row.dataset_id]\n",
    "    \n",
    "    try:\n",
    "        mask = grid == row.well\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "    # Figure out which directory to use\n",
    "#     if row.score == 0:\n",
    "#         twostate_path = [p_eval_tneg, p_eval_fpos][row.pred_twostate]\n",
    "#     elif row.score == 1:\n",
    "#         twostate_path = [p_eval_fneg, p_eval_tpos][row.pred_twostate]\n",
    "#     else:\n",
    "    twostate_path = [p_eval_uneg, p_eval_upos][row.pred_twostate]\n",
    "    \n",
    "    save_image_with_mask(row.image, mask, twostate_path / row.filename)\n",
    "    \n",
    "# Write images with three-state classification\n",
    "for row in output_df.itertuples():\n",
    "    \n",
    "    if row.dataset_id in list(dataset_new_ids):\n",
    "        oid = list(dataset_ids[dataset_new_ids==row.dataset_id].values)[0]\n",
    "        grid = grids[oid]\n",
    "    else:\n",
    "        grid = grids[row.dataset_id]\n",
    "    \n",
    "    try:\n",
    "        mask = grid == row.well\n",
    "        threestate_path = [p_tri_neg, p_tri_unk, p_tri_pos][row.pred_threestate]\n",
    "        save_image_with_mask(row.image, mask, threestate_path / row.filename)\n",
    "    except:\n",
    "        print(\"Error\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
