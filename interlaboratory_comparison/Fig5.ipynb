{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35edc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from definitions import ROOT_DIR\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, rc_context\n",
    "import matplotlib\n",
    "from anndata import AnnData\n",
    "from seriate import seriate\n",
    "import scanpy as sc\n",
    "from scipy.spatial.distance import pdist\n",
    "# from plotnine import *\n",
    "import re\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "rc('font',**{'family':'sans-serif',\n",
    "             'sans-serif':['Arial'],\n",
    "             'size':12})\n",
    "\n",
    "#Returns list of hard-coded paths (to avoid repetition in multiple function definitions)\n",
    "def paths():\n",
    "    p_root_dir = Path(ROOT_DIR)\n",
    "    p_data = p_root_dir / \"data\"\n",
    "    p_out = p_root_dir / \"test\"\n",
    "\n",
    "    # Compounds name and ID information\n",
    "    p_compounds = p_data / \"compounds_ids.csv\"\n",
    "\n",
    "    # Compound mapping to wells\n",
    "    p_wellmap = p_data / \"wellmap.csv\"\n",
    "\n",
    "    # Dataset info (lab, matrix, polarity, m/z range, ids, etc.)\n",
    "    p_datasets = p_data / \"Datasets_18Jan2023.csv\"\n",
    "\n",
    "    # Classification\n",
    "    p_chem_class = p_data / \"custom_classification_v2.csv\"\n",
    "    p_pathways = p_data / \"pathways_v2.csv\"\n",
    "    p_predictions = p_data / \"2022-08-16_All_Interlab_Predictions.csv\"\n",
    "\n",
    "    paths = {\n",
    "            'p_root_dir' : p_root_dir,\n",
    "            'p_data' : p_data,\n",
    "            'p_out' : p_out,\n",
    "            'p_compounds' : p_compounds,\n",
    "            'p_wellmap' : p_wellmap,\n",
    "            'p_datasets' : p_datasets,\n",
    "            'p_chem_class' : p_chem_class,\n",
    "            'p_pathways' : p_pathways,\n",
    "            'p_predictions' : p_predictions\n",
    "    }\n",
    "    return paths\n",
    "\n",
    "#Format ion formulas to publication standard\n",
    "def pretty_ion_formulas(adnl, pol=\"\"):\n",
    "    \n",
    "    adnl = [string.replace(\"[M]-\",\"\") for string in adnl]\n",
    "    adnl = [string.replace(\"[M]+\",\"\") for string in adnl]\n",
    "    adnl = [string.replace(\"++\",\"+\") for string in adnl]\n",
    "    adnl = [string.replace(\"--\",\"-\") for string in adnl]\n",
    "    adnl = [re.sub('([0-9])', '$_\\\\1$', string) for string in adnl]\n",
    "    adnl = ['[M'+string+']' for string in adnl]\n",
    "    if pol == 'Pos':\n",
    "        adnl = [string+'$^+$' for string in adnl]\n",
    "    elif pol == 'Neg':\n",
    "        adnl = [string+'$^-$' for string in adnl]\n",
    "    return adnl\n",
    "\n",
    "#Calculate and store peaks normalized to sum of peaks per molecule\n",
    "def calculate_signal_composition(df):\n",
    "    addlist = []\n",
    "    \n",
    "    for sample in list(set(df['sample_name'])): #For each dataset (one polarity, full range)\n",
    "        \n",
    "        for molecule in list(set(df[df['sample_name']==sample]['name_short'])): #For each unique named molecule\n",
    "            \n",
    "            #Sum up intensities of all matching adduct/neutral loss peaks and store\n",
    "            molsum = sum(df[(df['sample_name']==sample) & (df['name_short']==molecule)]['spot_intensity_bgr_corrected'])\n",
    "            addlist.append({'sample_name':sample, 'name_short':molecule, 'molsum':molsum})\n",
    "    \n",
    "    #Add sum intensity information to main dataframe\n",
    "    addf = pd.DataFrame(addlist)\n",
    "    newdf = pd.merge(df, addf, left_on=['sample_name','name_short'], right_on=['sample_name','name_short'], how='left')\n",
    "    \n",
    "    #Calculate the signal contribution of each row as intensity divided by total intensity\n",
    "    newdf['frac'] = newdf['spot_intensity_bgr_corrected']/newdf['molsum']\n",
    "    return newdf\n",
    "\n",
    "#Load csv files and organize dataframe\n",
    "def prepare_df(paths):\n",
    "\n",
    "    #Load predictions\n",
    "    predictions = pd.read_csv(paths['p_predictions'], index_col=0)\n",
    "    predictions.neutral_loss.fillna('', inplace=True)\n",
    "\n",
    "    #Load metadata files\n",
    "    compounds = pd.read_csv(paths['p_compounds'], index_col='internal_id')\n",
    "    wellmap = pd.read_csv(paths['p_wellmap'], index_col='internal_id')\n",
    "    chem_class = pd.read_csv(paths['p_chem_class'], index_col='internal_id')\n",
    "    pathways = pd.read_csv(paths['p_pathways'], index_col='internal_id')\n",
    "    datasets = pd.read_csv(paths['p_datasets'])\n",
    "    \n",
    "    #Load class data. WARNING: risk of duplication\n",
    "    main_chem_class = chem_class[['name_short', 'main_coarse_class']].drop_duplicates()\n",
    "\n",
    "    # Get a subset of most relevant information from Datasets file and add a unique sample name to each merged dataset (full mass range, single polarity)\n",
    "    datasets_info = datasets.groupby('Dataset ID').first()[['Polarity', 'Participant lab', 'Slide code', 'All', 'EMBL', 'Interlab', 'Technology', 'Matrix short']] # 'Participant lab', 'Technology'\n",
    "    datasets_info['sample_name'] = datasets_info['Slide code'] + ': ' + datasets_info['Technology'] + ': ' + datasets_info['Matrix short']\n",
    "\n",
    "    # Merge with predictions\n",
    "    df = pd.merge(predictions, datasets_info, left_on='dataset_id', right_on='Dataset ID', how='left')\n",
    "    df.sort_values(by = ['adduct', 'neutral_loss'], inplace=True)\n",
    "    \n",
    "    #Format adduct/neutral loss to output-ready format\n",
    "    df['neutral_loss'] = df['neutral_loss'].apply(lambda x: x if len(x) < 7 else '+Matrix')\n",
    "    df['adduct_and_nl'] = pretty_ion_formulas(df.adduct+df.neutral_loss)\n",
    "    df['Polarity'] = [('Pos' if x=='positive' else 'Neg') for x in df['Polarity']] \n",
    "    \n",
    "    #Remove duplicates\n",
    "#    df['problems'] = df['sample_name'] + \"  \" + df['Polarity'] + \", molecule: \" + df['name_short'] + df['adduct_and_nl']\n",
    "#    df.sort_values(by='pred_val', ascending=False)\n",
    "#    df['dupemask']=df.duplicated(subset='problems', keep='first')\n",
    "#    df = df[~df.dupemask].drop(['dupemask','problems'], axis='columns')\n",
    "#    df = df.sort_index()\n",
    "    \n",
    "    #Merge in metadata, apply filters\n",
    "    df = df[df['neutral_loss'] != '+HCl']\n",
    "    df = df.merge(main_chem_class, on='name_short', how='left')\n",
    "    df = df[df['Interlab']]\n",
    "    df = df[df['pred_threestate']==2]\n",
    "    df = calculate_signal_composition(df)\n",
    "    df = df.drop_duplicates(subset=['sample_name','name_short','adduct_and_nl'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_neutral_losses(df, filter_on=True, neutral_losses_to_keep=['']):\n",
    "    '''\n",
    "    Filter out entries for ions with neutral losses that are not in the list provided\n",
    "    '''\n",
    "    if filter_on==True:\n",
    "        df = df[df.neutral_loss.isin(neutral_losses_to_keep)]\n",
    "    elif filter_on == 'only_nl':\n",
    "        df = df[df.neutral_loss != '']\n",
    "    return df\n",
    "\n",
    "def calculate_detected_intensities(df):\n",
    "    '''\n",
    "    Make a column with background corrected intensities for detected compounds, and 0s for not detected compounds\n",
    "    Change any negative values to zero\n",
    "    '''\n",
    "    intensities_for_twostate_spots = (df.pred_twostate == 1) * df.spot_intensity_bgr_corrected\n",
    "    df['val_twostate'] = np.clip(intensities_for_twostate_spots, 0, None)\n",
    "    intensities_for_threestate_spots = (df.pred_threestate == 2) * df.spot_intensity_bgr_corrected\n",
    "    df['val_threestate'] = np.clip(intensities_for_threestate_spots, 0, None)\n",
    "    return df\n",
    "\n",
    "def filter_polarity(df, polarity):\n",
    "    '''\n",
    "    Filter out entries based on polarity pol ['pos', 'neg']\n",
    "    '''\n",
    "    return df[df['Polarity'] == polarity]\n",
    "\n",
    "def group_by_molecule(df, intensity_col_name, prediction_col_name):\n",
    "    '''\n",
    "    Aggregate intensity and detection values per class\n",
    "    '''\n",
    "    \n",
    "    if intensity_col_name == 'val_threestate':\n",
    "        intensity_aggregation_func = lambda x: (x==2).any()\n",
    "    else: intensity_aggregation_func = lambda x: (x==1).any()\n",
    "            \n",
    "    \n",
    "    data = df.pivot_table(index=['name_short'],\n",
    "                          columns=['sample_name'],\n",
    "                          values=[intensity_col_name, prediction_col_name],\n",
    "                          aggfunc = {\n",
    "                                intensity_col_name : lambda x: np.log10(sum(x)+1),\n",
    "                                prediction_col_name : intensity_aggregation_func\n",
    "                          },\n",
    "                          fill_value=0,)\n",
    "    data = data.stack(level=1, dropna=False).reset_index()\n",
    "    # If no ions on a molecule were detected by matrix, prediction column contains fill value 0 instead of False, correct for that:\n",
    "    data.at[data[prediction_col_name] == 0, prediction_col_name] = False\n",
    "    return data\n",
    "\n",
    "def prep_molecule_data(data, polarity,  intensity_col_name, prediction_col_name, nl_filter_on=False, neutral_losses_to_keep=None):\n",
    "    '''\n",
    "    '''\n",
    "    data = filter_neutral_losses(data, nl_filter_on, neutral_losses_to_keep)\n",
    "    data = calculate_detected_intensities(data)\n",
    "    data = filter_polarity(data, polarity)\n",
    "    data = group_by_molecule(data, intensity_col_name, prediction_col_name)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def summarise_per_fine_class(df, fine_class_col_name, coarse_class_col_name, intensity_col_name, prediction_col_name):\n",
    "    \n",
    "    df['class_size'] =1\n",
    "    data = df.pivot_table(index=['sample_name'],\n",
    "                                   columns=[fine_class_col_name, coarse_class_col_name],\n",
    "                                   values=[intensity_col_name, prediction_col_name, 'class_size'],\n",
    "                                   aggfunc = {\n",
    "                                        'class_size':sum,\n",
    "                                        prediction_col_name : sum,\n",
    "                                        intensity_col_name : np.mean\n",
    "                                   },\n",
    "                                   fill_value=0)\n",
    "    \n",
    "    data = data.stack(level=[1,2], dropna=True).reset_index()\n",
    "    data['fraction_detected'] = data[prediction_col_name] / data['class_size']    \n",
    "    \n",
    "    # sort columns alphabetically\n",
    "    data = data.sort_values(by='sample_name')\n",
    "    # sort rows first by coarse class, then by fine class\n",
    "    data = data.sort_values(by=[coarse_class_col_name, fine_class_col_name])\n",
    "    return data\n",
    "\n",
    "def summarise_per_coarse_class(df, class_col_name, intensity_col_name, prediction_col_name):\n",
    "    \n",
    "    df['class_size'] = 1\n",
    "    data = df.pivot_table(index=['sample_name'],\n",
    "                                   columns=class_col_name,\n",
    "                                   values=[intensity_col_name, prediction_col_name, 'class_size'],\n",
    "                                   aggfunc = {\n",
    "                                        'class_size':sum,\n",
    "                                        prediction_col_name : sum,\n",
    "                                        intensity_col_name : np.mean\n",
    "                                   },\n",
    "                                   fill_value=0)\n",
    "    \n",
    "    data = data.stack(level=1, dropna=False).reset_index()\n",
    "    data['fraction_detected'] = data[prediction_col_name] / data['class_size']\n",
    "    \n",
    "    \n",
    "    # sort columns alphabetically\n",
    "    data = data.sort_values(by='sample_name')    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea2a6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_df(paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a98a8",
   "metadata": {},
   "source": [
    "# Interlab heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e5ea28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saharuka\\AppData\\Local\\Temp\\ipykernel_8188\\885082108.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['val_twostate'] = np.clip(intensities_for_twostate_spots, 0, None)\n",
      "C:\\Users\\saharuka\\AppData\\Local\\Temp\\ipykernel_8188\\885082108.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['val_threestate'] = np.clip(intensities_for_threestate_spots, 0, None)\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "You can only assign a scalar value not a <class 'bool'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\batch\\lib\\site-packages\\pandas\\core\\frame.py:4209\u001b[0m, in \u001b[0;36mDataFrame._set_value\u001b[1;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[0;32m   4208\u001b[0m     icol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(col)\n\u001b[1;32m-> 4209\u001b[0m     iindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mcolumn_setitem(icol, iindex, value)\n",
      "File \u001b[1;32m~\\.conda\\envs\\batch\\lib\\site-packages\\pandas\\core\\indexes\\range.py:394\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "File \u001b[1;32m~\\.conda\\envs\\batch\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5968\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5966\u001b[0m     \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5967\u001b[0m     \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5968\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: 0        True\n1       False\n2       False\n3       False\n4        True\n        ...  \n2101    False\n2102    False\n2103    False\n2104    False\n2105    False\nName: pred_threestate, Length: 2106, dtype: bool",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pol \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeg\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     molecule_data \u001b[38;5;241m=\u001b[39m \u001b[43mprep_molecule_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mpolarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mnl_filter_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mneutral_losses_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mintensity_col_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_threestate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mprediction_col_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred_threestate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Map chemical classes\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     chem_class \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(paths()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_chem_class\u001b[39m\u001b[38;5;124m'\u001b[39m], index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minternal_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 192\u001b[0m, in \u001b[0;36mprep_molecule_data\u001b[1;34m(data, polarity, intensity_col_name, prediction_col_name, nl_filter_on, neutral_losses_to_keep)\u001b[0m\n\u001b[0;32m    190\u001b[0m data \u001b[38;5;241m=\u001b[39m calculate_detected_intensities(data)\n\u001b[0;32m    191\u001b[0m data \u001b[38;5;241m=\u001b[39m filter_polarity(data, polarity)\n\u001b[1;32m--> 192\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mgroup_by_molecule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintensity_col_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_col_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "Cell \u001b[1;32mIn[6], line 183\u001b[0m, in \u001b[0;36mgroup_by_molecule\u001b[1;34m(df, intensity_col_name, prediction_col_name)\u001b[0m\n\u001b[0;32m    181\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mstack(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# If no ions on a molecule were detected by matrix, prediction column contains fill value 0 instead of False, correct for that:\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m data\u001b[38;5;241m.\u001b[39mat[data[prediction_col_name] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, prediction_col_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\.conda\\envs\\batch\\lib\\site-packages\\pandas\\core\\indexing.py:2442\u001b[0m, in \u001b[0;36m_AtIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m   2440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 2442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\batch\\lib\\site-packages\\pandas\\core\\indexing.py:2397\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m   2395\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough indexers for scalar access (setting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2397\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\batch\\lib\\site-packages\\pandas\\core\\frame.py:4227\u001b[0m, in \u001b[0;36mDataFrame._set_value\u001b[1;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[0;32m   4222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_cache\u001b[38;5;241m.\u001b[39mpop(col, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidIndexError \u001b[38;5;28;01mas\u001b[39;00m ii_err:\n\u001b[0;32m   4225\u001b[0m     \u001b[38;5;66;03m# GH48729: Seems like you are trying to assign a value to a\u001b[39;00m\n\u001b[0;32m   4226\u001b[0m     \u001b[38;5;66;03m# row when only scalar options are permitted\u001b[39;00m\n\u001b[1;32m-> 4227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\n\u001b[0;32m   4228\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can only assign a scalar value not a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4229\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mii_err\u001b[39;00m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: You can only assign a scalar value not a <class 'bool'>"
     ]
    }
   ],
   "source": [
    "for pol in ['Pos', 'Neg']:\n",
    "    molecule_data = prep_molecule_data(df,\n",
    "                                       polarity=pol, \n",
    "                                       nl_filter_on=True, \n",
    "                                       neutral_losses_to_keep=[''], \n",
    "                                       intensity_col_name= 'val_threestate',\n",
    "                                       prediction_col_name = 'pred_threestate')\n",
    "\n",
    "    # Map chemical classes\n",
    "    chem_class = pd.read_csv(paths()['p_chem_class'], index_col='internal_id')\n",
    "    mapped_data = molecule_data.merge(chem_class, on='name_short', how='left')\n",
    "\n",
    "    class_data = summarise_per_coarse_class(mapped_data,\n",
    "                                                class_col_name='main_coarse_class',\n",
    "                                                intensity_col_name= 'val_threestate',\n",
    "                                                prediction_col_name = 'pred_threestate')\n",
    "\n",
    "\n",
    "    plot_data = class_data.pivot_table(index = ['sample_name'],\n",
    "                                           columns=['main_coarse_class'],\n",
    "                                           values=['fraction_detected'],\n",
    "                                           aggfunc = {\n",
    "                                                'fraction_detected':sum,\n",
    "                                           },\n",
    "                                           fill_value=0).T\n",
    "    plot_data = plot_data.reindex(columns=plot_data.columns[seriate(pdist(plot_data.T.to_numpy()))])\n",
    "\n",
    "    plot_data.to_csv(paths()['p_data'] / f'Plot_Data_{pol}.csv')\n",
    "    \n",
    "    plt.figure(figsize=[12,8])\n",
    "    sns.heatmap(data=plot_data, \n",
    "                    yticklabels=plot_data.index.get_level_values(1), \n",
    "                    cmap='viridis',\n",
    "                    cbar_kws={'label': 'Fraction Detected'}\n",
    "                   )\n",
    "    #plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "    plt.title(f\"{pol}\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    #plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(paths()['p_out'] / f\"Heatmap_{pol}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64204026",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1790beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_size(metadata, class_column):\n",
    "    sizes = metadata[class_column].value_counts()\n",
    "    metadata['class_size'] = [sizes[k] for k in metadata[class_column]]\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def filter_neutral_losses(df, neutral_losses=['']):\n",
    "    '''\n",
    "    Filter out entries for ions with neutral losses that are not in the list provided\n",
    "    If neutral_loss value us \"only_nl\", than consider only ions that have neutral losses\n",
    "    '''\n",
    "    \n",
    "    if neutral_losses == \"only_nl\":\n",
    "        df = df[df.neutral_loss != \"\"]\n",
    "    elif neutral_losses != None:\n",
    "        df = df[df.neutral_loss.isin(neutral_losses)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_adducts(df, adducts=['']):\n",
    "    '''\n",
    "    Filter out entries for ions with adducts that are not in the list provided\n",
    "    '''\n",
    "    if adducts != None:\n",
    "        df = df[df.adduct.isin(adducts)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_polarity(df, polarity=None):\n",
    "    '''\n",
    "    Filter out entries based on polarity pol ['positive', 'negative']\n",
    "    '''\n",
    "    if polarity != None:\n",
    "        df = df[df.Polarity == polarity]\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_data(data, polarity=None, adducts=None, neutral_losses=None):\n",
    "    '''\n",
    "    Apply polarity, adduct and neutral_loss filters\n",
    "    '''\n",
    "    data = filter_polarity(data, polarity)\n",
    "    data = filter_adducts(data, adducts)\n",
    "    data = filter_neutral_losses(data, neutral_losses)\n",
    "    return data\n",
    "\n",
    "\n",
    "def group_by_molecule(df, groupby_columns):\n",
    "    '''\n",
    "    Aggregate intensity and detection values per groupby columns\n",
    "    '''          \n",
    "    data = df.groupby(groupby_columns).agg({\n",
    "        'detectability' : 'max', # here detectability of metabolite is set to 1 if any of it's ions was detected\n",
    "        'property1' : 'sum', # here the additional property is summed across all detected ions of metabolite\n",
    "        'property2' : 'sum', # here the additional property is summed across all detected ions of metabolite\n",
    "        'property3' : 'sum' # here the additional property is summed across all detected ions of metabolite\n",
    "    }).reset_index()\n",
    "    return data\n",
    "\n",
    "\n",
    "def summarise_per_class(df, groupby_columns):\n",
    "    \n",
    "    data = df.groupby(groupby_columns).agg({'detectability' : 'sum', # here number of detected metabolites per class is counted\n",
    "                                            'my_property' : 'mean', # here you take a mean of some property among all detected metabolites in that class\n",
    "                                            'class_size': 'first'\n",
    "                                            }).reset_index()\n",
    "\n",
    "    data['fraction_detected'] = data.detectability / data['class_size'] \n",
    "    data.drop(columns=['detectability', 'class_size'], inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def assemble_adata(pca):\n",
    "    observables = pca.index.to_frame(index=False)\n",
    "    for col in observables.columns:\n",
    "        observables[col] = observables[col].astype('category')  \n",
    "    variables = pca.columns.to_frame(index=False)\n",
    "    adata = AnnData(pca.values, obs=observables, var=variables)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d7f6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_root_dir = Path(ROOT_DIR)\n",
    "p_data = p_root_dir / \"data\"\n",
    "p_out = p_root_dir / \"test\"\n",
    "\n",
    "# Metrics and Catboost predictions for all ions in their target wells\n",
    "p_predictions = p_data / \"2022-08-16_All_Interlab_Predictions.csv\"\n",
    "\n",
    "# Dataset info (lab, matrix, polarity, m/z range, ids, etc.)\n",
    "p_datasets = p_data / \"Datasets_18Jan2023.csv\"\n",
    "\n",
    "# Classification\n",
    "p_chem_class = p_data / \"custom_classification_v2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceac8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format neutral loss column, keep other columns that you need\n",
    "predictions = pd.read_csv(p_predictions, index_col=0)\n",
    "\n",
    "\n",
    "predictions.neutral_loss.fillna('', inplace=True)\n",
    "\n",
    "# Add dataset metadata \n",
    "datasets = pd.read_csv(p_datasets)\n",
    "metadata_columns = ['Dataset name', \n",
    "                    'Participant lab', \n",
    "                    'Technology', \n",
    "                    'Original technology', \n",
    "                    'Ionisation source',\n",
    "                    'Mass analyser', \n",
    "                    'Source pressure',\n",
    "                    'Matrix short',\n",
    "                    'Polarity', \n",
    "                    'Slide code',\n",
    "                    'Interlab', \n",
    "                    'All'\n",
    "                   ]\n",
    "datasets_info = datasets.groupby('Dataset ID').first()[metadata_columns]\n",
    "\n",
    "# Merge with predictions\n",
    "df = pd.merge(predictions, datasets_info, left_on='dataset_id', right_on='Dataset ID', how='left')\n",
    "\n",
    "# Filter to keep only interlab datasets + EMBL datasets with 10ppm\n",
    "df = df[df['Interlab']] \n",
    "# only consider data of detected ions\n",
    "threshold = 0.8\n",
    "df['detectability'] = df.pred_val >= threshold\n",
    "data = df[df.detectability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "configured-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.stack(1).to_csv(p_out / \"pca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "accessory-chile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 16 × 162\n",
       "    obs: 'Dataset name', 'Participant lab', 'Technology', 'Original technology', 'Ionisation source', 'Mass analyser', 'Source pressure', 'Matrix short', 'Polarity', 'Slide code', 'Interlab', 'All'\n",
       "    var: 0, 'name_short', 'mean', 'std'\n",
       "    uns: 'pca'\n",
       "    obsm: 'X_pca'\n",
       "    varm: 'PCs'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a73cbf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose polarity, filter adducts and neutral losses\n",
    "filtered_data = filter_data(data,\n",
    "                            polarity='positive', \n",
    "                            neutral_losses=['']\n",
    "                           )\n",
    "\n",
    "# Add property that you want to use for PCA\n",
    "filtered_data['property1'] = filtered_data['on_off_ratio'] * 1 # this is just an example that does nothing to the column, but you can do whatever\n",
    "filtered_data['property2'] = filtered_data['spot_intensity_bgr_corrected_tic_norm'] * 1\n",
    "filtered_data['property3'] = filtered_data['bg_intensity_tic'] * 1\n",
    "\n",
    "# Summarise data per metabolite and dataset\n",
    "molecule_data = group_by_molecule(filtered_data, groupby_columns=np.append(metadata_columns, 'name_short').tolist())\n",
    "\n",
    "# Reshape\n",
    "pca = molecule_data.pivot_table(values=['detectability'], # you can choose one or more of propeties for pca, the one I sent you is only using detectability \n",
    "                                 index=metadata_columns, \n",
    "                                 columns='name_short',\n",
    "                                 fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04a6e4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saharuka\\AppData\\Local\\Temp\\ipykernel_8188\\98761730.py:78: FutureWarning: X.dtype being converted to np.float32 from int64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  adata = AnnData(pca.values, obs=observables, var=variables)\n",
      "C:\\Users\\saharuka\\.conda\\envs\\batch\\lib\\site-packages\\anndata\\_core\\anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Assemble adata\n",
    "adata = assemble_adata(pca)\n",
    "\n",
    "# Apply Z-score normalisation: If you use only detectability for PCA, this is not needed\n",
    "sc.pp.scale(adata, zero_center=True) \n",
    "\n",
    "# Compute PCA\n",
    "sc.tl.pca(adata, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e143a979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saharuka\\.conda\\envs\\batch\\lib\\site-packages\\scanpy\\plotting\\_tools\\scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "C:\\Users\\saharuka\\.conda\\envs\\batch\\lib\\site-packages\\scanpy\\plotting\\_tools\\scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "C:\\Users\\saharuka\\.conda\\envs\\batch\\lib\\site-packages\\scanpy\\plotting\\_tools\\scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "C:\\Users\\saharuka\\.conda\\envs\\batch\\lib\\site-packages\\scanpy\\plotting\\_tools\\scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "C:\\Users\\saharuka\\.conda\\envs\\batch\\lib\\site-packages\\scanpy\\plotting\\_tools\\scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "C:\\Users\\saharuka\\.conda\\envs\\batch\\lib\\site-packages\\scanpy\\plotting\\_tools\\scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "C:\\Users\\saharuka\\.conda\\envs\\batch\\lib\\site-packages\\scanpy\\plotting\\_tools\\scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "C:\\Users\\saharuka\\.conda\\envs\\batch\\lib\\site-packages\\scanpy\\plotting\\_tools\\scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "C:\\Users\\saharuka\\AppData\\Local\\Temp\\ipykernel_8188\\4151968780.py:23: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "meta NOT subset; don't know how to subset; dropped\n"
     ]
    }
   ],
   "source": [
    "fname = \"PCA_interlab_coarse_class_neg\"\n",
    "\n",
    "with rc_context():    \n",
    "    ax = sc.pl.pca(adata, \n",
    "                   components=['1, 2'], \n",
    "                   color=[\n",
    "#                     'Dataset name', \n",
    "                    'Participant lab', \n",
    "                    'Technology', \n",
    "                    'Original technology', \n",
    "                    'Ionisation source',\n",
    "                    'Mass analyser', \n",
    "                    'Source pressure',\n",
    "                    'Matrix short',\n",
    "                    'Polarity', \n",
    "                   ],\n",
    "                   size=400, \n",
    "                   ncols=2,\n",
    "                   legend_loc='right margin',\n",
    "                   show=False, \n",
    "                   wspace=0.7,\n",
    "                   annotate_var_explained = True)\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(p_out/ f\"{fname}.png\")\n",
    "    plt.savefig(p_out / f\"{fname}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5bca9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-batch]",
   "language": "python",
   "name": "conda-env-.conda-batch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
