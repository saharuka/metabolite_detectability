{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# If using Jupyter Lab, use widget instead of notebook\n",
    "%pylab widget --no-import-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigger plots\n",
    "plt.rcParams['figure.figsize'] = 15, 10\n",
    "# Wider maximum width of pandas columns (needed to see the full lists of molecules)\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install dependencies: pip install metaspace2020>=1.7.2 scikit-learn scikit-image seaborn matplotlib pandas numpy pyimzml\n",
    "from getpass import getpass\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from metaspace.sm_annotation_utils import SMInstance\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.draw import ellipse\n",
    "import seaborn as sns\n",
    "from pyimzml.ImzMLParser import ImzMLParser\n",
    "from pyimzml.ImzMLWriter import ImzMLWriter\n",
    "# \"definitions\" is part of the metabolite_analysis repo. \n",
    "# If the following line doesn't work, check you're in the \n",
    "# right conda environment and `pip install -e .` in the \n",
    "# metabolite_analysis directory\n",
    "from definitions import ROOT_DIR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transform(from_, to):\n",
    "    \"\"\" \n",
    "    Estimate the coordinate-space transform to map coordinates in `from_` to the values in `to`.\n",
    "    Returns a function to convert from `from_`-space to `to`-space\n",
    "    \"\"\"\n",
    "    from_padded = [(*c, 1) for c in from_]\n",
    "    to_padded = [(*c, 1) for c in to]\n",
    "    res = np.linalg.lstsq(from_padded, to_padded, rcond=None)\n",
    "    mat = res[0]\n",
    "\n",
    "    def transform(*x):\n",
    "        if len(x) == 1 and isinstance(x[0], tuple):\n",
    "            x = x[0]\n",
    "        return np.dot([*x, 1], mat)[:-1]\n",
    "\n",
    "    return transform\n",
    "\n",
    "\n",
    "def make_mask(h, w, positions, grid_coords, n_rows, n_cols, spot_h, spot_w, alternating_rows):\n",
    "    \"\"\"\n",
    "    Calculates a mask where each pixel value indicates which spot it's in, with `0` meaning 'background'.\n",
    "    Returns the 2d mask, and a list mapping values to spot names (e.g. '0_1' for row 0 column 1).\n",
    "    \"\"\"\n",
    "    cell_to_position = make_transform(grid_coords, positions)\n",
    "    rx, ry = spot_h / 2, spot_w / 2\n",
    "    mask = np.zeros((h, w), np.int32)\n",
    "    mask_names = ['background']\n",
    "    \n",
    "    i = 1\n",
    "    for y in range(n_rows):\n",
    "        odd = alternating_rows and y % 2 == 1\n",
    "        xs = range(n_cols - 1 if odd else n_cols) # Use 1 fewer column on odd rows\n",
    "        for x in xs:\n",
    "            yc, xc = cell_to_position(y, x + 0.5 if odd else x)\n",
    "            # Snap the calculated coordinates to the pixel grid so that generated ellipses have the same shape\n",
    "            yc = round(yc) + 0.5 - ry % 1\n",
    "            xc = round(xc) + 0.5 - rx % 1\n",
    "            xx, yy = ellipse(yc, xc, ry, rx, (h, w))\n",
    "            mask[xx, yy] = i\n",
    "            mask_names.append(f'{y}_{x}')\n",
    "            i += 1\n",
    "    return mask, mask_names\n",
    "\n",
    "\n",
    "def colorize_mask(mask):\n",
    "    \"\"\"\n",
    "    Converts each mask value to a color, with background values being fully transparent. \n",
    "    For visualization only.\n",
    "    \"\"\"\n",
    "    cnt = np.max(mask)\n",
    "    print(cnt)\n",
    "    palette = [\n",
    "        (0,0,0,0),\n",
    "        *[(r,g,b,0.5) for r,g,b in sns.color_palette('hls', int(cnt))]\n",
    "    ]\n",
    "    image = np.empty((*mask.shape, 4))\n",
    "    print(image.shape)\n",
    "    for (y, x), val in np.ndenumerate(mask):\n",
    "        image[y, x, :] = palette[val]\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log in to METASPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hidden feature:** If you make a file containing your API key, `SMInstance` will automatically log in and you won't need to enter your API key every time.\n",
    "\n",
    "You can create this file with:\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "Path('~/.metaspace').open('w').write('api_key=XXXXXX' + '\\n')\n",
    "```\n",
    "\n",
    "*(replace the XXXXXX with you actual API key)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMInstance()\n",
    "if not sm.logged_in():\n",
    "    print('Enter your API key from https://metaspace2020.eu/user/me')\n",
    "    sm.login(api_key=getpass())\n",
    "else:\n",
    "    print('Already logged in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a dataset and download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a dataset and database/fdr for the images to use for alignment in the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = '2020-03-12_17h55m21s'\n",
    "fdr = 0.5\n",
    "database = 'SwissLipids-2018-02-02' # or 'HMDB-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input/output paths\n",
    "input_grid_file = Path(ROOT_DIR) / 'data' / 'input_grids' / f'{dataset_id}.json'\n",
    "output_mask_file = Path(ROOT_DIR) / 'data' / 'grid_masks' / f'{dataset_id}.npy'\n",
    "output_mask_names_file = Path(ROOT_DIR) / 'data' / 'grid_masks' / f'{dataset_id}_mask_names.json'\n",
    "\n",
    "# Download annotations & images\n",
    "annotations = sm.get_annotations(fdr, database, {'ids': dataset_id})\n",
    "images = sm.dataset(id=dataset_id).all_annotation_images(fdr, database, True, True)\n",
    "# Put images into a dictionary for easy lookup\n",
    "images = dict(((img.formula, img.adduct), img[0]) for img in images)\n",
    "# Get width & height\n",
    "h, w = next(iter(images.values())).shape\n",
    "# Create a 2D numpy array where each row is a linearized 1D image, \n",
    "# for easy simultaneous manipulation of all images\n",
    "images_flat = np.array(list(images.values())).reshape(len(images), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find a good image to help with alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual ion images usually aren't great for alignment.\n",
    "# This just calculates 4 types of summary images - usually one or two will\n",
    "# clearly show a wide selection of spots, which helps a lot.\n",
    "pca = PCA(2, whiten=True)\n",
    "pca.fit(images_flat)\n",
    "\n",
    "def prep_image(flat_image):\n",
    "    img = np.clip(flat_image, np.percentile(flat_image, 1), np.percentile(flat_image, 99)).reshape(h, w)\n",
    "    img -= np.min(img)\n",
    "    return img\n",
    "\n",
    "pca0_image = prep_image(pca.components_[0])\n",
    "pca1_image = prep_image(pca.components_[1])\n",
    "sum_int_image = prep_image(np.sum(images_flat, axis=0))\n",
    "sum_norm_image = prep_image(np.sum(images_flat / np.sum(images_flat, axis=1, keepdims=True), axis=0))\n",
    "plt.close('all')\n",
    "plt.subplot(2,2,1, title='pca0_image')\n",
    "plt.imshow(pca0_image)\n",
    "plt.subplot(2,2,2, title='pca1_image')\n",
    "plt.imshow(pca1_image)\n",
    "plt.subplot(2,2,3, title='sum_int_image')\n",
    "plt.imshow(sum_int_image)\n",
    "plt.subplot(2,2,4, title='sum_norm_image')\n",
    "plt.imshow(sum_norm_image)\n",
    "plt.autoscale(tight=True)\n",
    "plt.subplots_adjust(left=0, right=1, top=0.95, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uncomment the line for one of the above guide images to be used for alignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_image = pca0_image\n",
    "# example_image = pca1_image\n",
    "# example_image = sum_int_image\n",
    "example_image = sum_norm_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create grid calibration file (if it doesn't already exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This writes a template JSON file as a starting point for alignment\n",
    "# The \"help:\" fields aren't actually used, it's just an easy way to leave inline comments in JSON\n",
    "# If the file already exists, this doesn't do anything\n",
    "if not input_grid_file.exists():\n",
    "    input_grid_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    n_rows, n_cols = 21, 10\n",
    "    input_grid_file.open('w').write(f\"\"\"\n",
    "{{\n",
    "    \"help:general\": \"Keep in mind that json is a different format and much less forgiving than Python. Don't add a comma after the last item in a list, and keep true/false lower-case\",\n",
    "    \"help:positions\": \"Pixel coordinates of the centers of calibration spots [y, x]\",\n",
    "    \"positions\": [[0, 0], [0, {w}], [{h}, 0], [{h}, {w}]],\n",
    "    \"help:grid_coords\": \"Grid coordinates of the calibration spots. Same spot order as positions. [row, col]\",\n",
    "    \"grid_coords\": [[0, 0], [0, {n_cols-1}], [{n_rows-1}, 0], [{n_rows-1}, {n_cols-1}]],\n",
    "    \"help:n_rows_n_cols\": \"Size of the grid\",\n",
    "    \"n_rows\": 21,\n",
    "    \"n_cols\": 10,\n",
    "    \"help:spot_h_spot_w\": \"Height / width of each spot\",\n",
    "    \"spot_h\": 7,\n",
    "    \"spot_w\": 7,\n",
    "    \"help:image_h_image_w\": \"Image dimensions (should not be adjusted)\",\n",
    "    \"image_h\": {h},\n",
    "    \"image_w\": {w},\n",
    "    \"help:alternating_rows\": \"'true' if every odd-numbered row is shifted, 'false' for a rectangular grid\",\n",
    "    \"alternating_rows\": true\n",
    "}}\n",
    "    \"\"\")\n",
    "    print(f\"Created {input_grid_file.resolve()}\")\n",
    "else:\n",
    "    print(f\"Grid calibration file already exists at {input_grid_file.resolve()}\")\n",
    "print(\"Now open this file in another editor and adjust the parameters while re-running the below cell to calibrate the grid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test grid calibration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the calibration file\n",
    "input_grid = json.load(input_grid_file.open('r'))\n",
    "# Convert it to a mask\n",
    "grid_mask, mask_names = make_mask(\n",
    "    h, w,\n",
    "    input_grid['positions'], \n",
    "    input_grid['grid_coords'], \n",
    "    input_grid['n_rows'], \n",
    "    input_grid['n_cols'], \n",
    "    input_grid['spot_h'], \n",
    "    input_grid['spot_w'],\n",
    "    input_grid['alternating_rows'],\n",
    ")\n",
    "# Display the mask over the top of the guide image\n",
    "plt.close('all')\n",
    "plt.imshow(example_image)\n",
    "plt.imshow(colorize_mask(grid_mask), interpolation='bilinear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When finished calibrating, save the mask for use in analysis steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mask_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "np.save(output_mask_file, grid_mask)\n",
    "output_mask_names_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "json.dump(mask_names, output_mask_names_file.open('w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metabolite]",
   "language": "python",
   "name": "conda-env-metabolite-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
