{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook adapted from original version by L.Stuart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:33.610129Z",
     "start_time": "2021-06-02T16:06:33.498927Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.264180Z",
     "start_time": "2021-06-02T16:06:33.940237Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.ndimage import binary_dilation\n",
    "from sklearn import clone\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from metaspace.sm_annotation_utils import SMInstance\n",
    "from metaspace.image_processing import clip_hotspots\n",
    "import getpass\n",
    "from metaspace import SMInstance\n",
    "from datetime import datetime\n",
    "from matplotlib.colors import Normalize, LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.285960Z",
     "start_time": "2021-06-02T16:06:34.265231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings, because many models spam them during feature selection\n",
    "# as some subsets of features just don't have enough information to make\n",
    "# a good model.\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.833722Z",
     "start_time": "2021-06-02T16:06:34.810682Z"
    }
   },
   "outputs": [],
   "source": [
    "def colorize_image_with_mask(image, mask):\n",
    "    \"\"\"Plotting function for combining a colorized ion image with a spot mask\"\"\"\n",
    "    \n",
    "    image = clip_hotspots(image)\n",
    "    image /= np.max(image)\n",
    "    \n",
    "    on_spot_colorized = plt.cm.cividis(image)\n",
    "    off_spot_colorized = plt.cm.magma(image)\n",
    "    return np.where(mask[:,:,np.newaxis], on_spot_colorized, off_spot_colorized)\n",
    "\n",
    "def make_a_panel(image, tic_image, mask):\n",
    "    \n",
    "    x = image.shape[1]\n",
    "    y = image.shape[0]\n",
    "\n",
    "    norm = Normalize() # This is a matplotlib tool to scale everything to the 0-1 range\n",
    "    log_norm = LogNorm() # Same, but it does a log transform before scaling to the 0-1 range\n",
    "    new_shape = (y, x*4 + 3, 4)  # The \"4\" is to fit that per-pixel RGBA dimension\n",
    "    \n",
    "    panel = np.zeros(shape=new_shape)\n",
    "    panel[0:y, 0:x] = colorize_image_with_mask(image, mask)\n",
    "    panel[0:y, x+1:2*x+1] = plt.cm.cividis(norm(clip_hotspots(image)))\n",
    "    panel[0:y, 2*x+2:3*x+2] = plt.cm.cividis(log_norm(image + 1))\n",
    "    panel[0:y, -x:] = plt.cm.cividis(Normalize()(clip_hotspots(tic_image)))    \n",
    "    return panel    \n",
    "    \n",
    "    \n",
    "def save_image_with_mask(image, mask, fname, tic_image):\n",
    "    plt.imsave(fname, make_a_panel(image, tic_image, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:35.191813Z",
     "start_time": "2021-06-02T16:06:35.170946Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_zeros(img):\n",
    "    \"\"\"Crop an image, removing all empty outer rows/columns\"\"\"\n",
    "    cols = np.flatnonzero(np.count_nonzero(img, axis=0) != 0)\n",
    "    rows = np.flatnonzero(np.count_nonzero(img, axis=1) != 0)\n",
    "    top = rows[0]\n",
    "    bottom = rows[-1] + 1\n",
    "    left = cols[0]\n",
    "    right = cols[-1] + 1\n",
    "\n",
    "    return img[top:bottom, left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:35.605701Z",
     "start_time": "2021-06-02T16:06:35.584102Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mispredictions(model, X, y):\n",
    "    \"\"\"\n",
    "    Find which values would be mispredicted, returning two lists:\n",
    "        * indexes of items that would be falsely predicted as positives\n",
    "        * indexes of items that would be falsely predicted as negatives\n",
    "        \n",
    "    cross_val_predict uses a shuffled 5-fold test-train split so that each chunk of \n",
    "    20% of the input data gets its own model that was trained on the other 80%, \n",
    "    ensuring that the items being predicted aren't included in the training data.\n",
    "    \"\"\"\n",
    "    preds = cross_val_predict(model, X, y)\n",
    "    mispreds = preds != y\n",
    "    fpos_idxs = np.flatnonzero(mispreds & ~y)\n",
    "    fneg_idxs = np.flatnonzero(mispreds & y)\n",
    "        \n",
    "    return fpos_idxs, fneg_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:36.849373Z",
     "start_time": "2021-06-02T16:06:36.826914Z"
    }
   },
   "outputs": [],
   "source": [
    "p_root_dir = Path.cwd().parents[0]\n",
    "\n",
    "p_analysis = p_root_dir  / \"4_apply_classifier\"\n",
    "p_grids = p_root_dir / \"2_grid_calibration/grid_masks\"\n",
    "p_wellmap = p_root_dir / \"5_data/metadata/wellmap.csv\"\n",
    "\n",
    "# Paths for model appication\n",
    "p_model = p_root_dir  /\"3_train_classifier\" / \"model_evaluation/model.json\"\n",
    "p_apply = p_analysis / \"model_application_best_replicates\"\n",
    "p_images = p_apply / \"images.hdf5\"\n",
    "p_datasets = p_apply / \"manual_dataset_qc.csv\"\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%d-%b-%Y\") \n",
    "p_predictions = p_apply / f\"all_predictions_{timestamp}.csv\"\n",
    "p_predictions_curated = p_apply / f\"all_predictions_curated_{timestamp}.csv\"\n",
    "p_metrics = p_apply / f\"metrics_{timestamp}.csv\"\n",
    "\n",
    "# False positives/negatives - preview output from model prediction for molecules with known labels\n",
    "# Note that all files in these directories are cleared before a prediction run\n",
    "p_apply_fpos = p_apply / 'false_positives'\n",
    "p_apply_fneg = p_apply / 'false_negatives'\n",
    "p_apply_tpos = p_apply / 'true_positives'\n",
    "p_apply_tneg = p_apply / 'true_negatives'\n",
    "# Unknown positives/negatives - preview output from model prediction for molecules with no label\n",
    "# Note that all files in these directories are cleared before a prediction run\n",
    "p_apply_upos = p_apply / 'unknown_positives'\n",
    "p_apply_uneg = p_apply / 'unknown_negatives'\n",
    "# Manually labeled positives/negatives - Move preview files from any of the above directories into \n",
    "# these directories to add to the labelled data. Make sure to re-run the appropriate steps \n",
    "# in \"Input data\" to detect the changes\n",
    "p_apply_lpos = p_apply / 'manual_label_positives'\n",
    "p_apply_lneg = p_apply / 'manual_label_negatives'\n",
    "\n",
    "# Directories for three-state positive/unsure/negative classification\n",
    "p_tri_pos = p_apply / 'three-state' / 'positive'\n",
    "p_tri_unk = p_apply / 'three-state' / 'unsure'\n",
    "p_tri_neg = p_apply / 'three-state' / 'negative'\n",
    "\n",
    "# METASPACE\n",
    "database = ('Spotting_project_compounds-v9', 'feb2021')\n",
    "fdr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into metaspace\n",
    "sm = SMInstance(host='https://metaspace2020.eu')\n",
    "\n",
    "if not sm.logged_in():\n",
    "    # Using getpass here prevents the API key from being accidentally saved with this notebook.\n",
    "    api_key = getpass.getpass(prompt='API key: ', stream=None)\n",
    "    sm.login(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:38.160316Z",
     "start_time": "2021-06-02T16:06:38.112047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dataset ids of interest  from dataset qc spreadsheet (corresponding grids should exist)\n",
    "datasets = pd.read_csv(p_datasets)\n",
    "dataset_subset = datasets[datasets.Selection == 'Yes']\n",
    "\n",
    "dataset_ids = dataset_subset['Clone ID']\n",
    "dataset_paths = [list(p_grids.rglob(f\"*{x}*.npy\"))[0] for x in dataset_ids]\n",
    "dataset_names = dataset_subset['Matrix short'] + '_' + dataset_subset['Polarity'] + '_' + dataset_subset['Slide code']\n",
    "dataset_names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:08:50.018554Z",
     "start_time": "2021-06-02T16:06:38.808059Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Images from METASPACE\n",
    "# Ignore any warnings about connection pools in this step\n",
    "\n",
    "p_apply.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, ds_id in enumerate(dataset_ids):\n",
    "    images = []\n",
    "    print(f'Downloading images for {ds_id} ({i}/{len(dataset_ids)})')\n",
    "    dataset = sm.dataset(id=ds_id)\n",
    "    ds_tic_image = dataset.tic_image()\n",
    "    for img in dataset.all_annotation_images(\n",
    "        fdr=fdr, \n",
    "        database=database, \n",
    "        only_first_isotope=True, \n",
    "        scale_intensity=True, \n",
    "        hotspot_clipping=False\n",
    "    ):\n",
    "        # Exclude annotations with no first-isotopic-image\n",
    "        if img[0] is not None:\n",
    "            images.append({\n",
    "                'dataset_id': ds_id,\n",
    "                'formula': img.formula,\n",
    "                'adduct': img.adduct,\n",
    "                'neutral_loss': img.neutral_loss or '',\n",
    "                'image': img[0],\n",
    "                'tic_norm_image': np.nan_to_num(img[0] / ds_tic_image),  # nan_to_num replaces nan values with 0.0. This line will probably complain about division by zero but it can be ignored as it's fixed by the nan_to_num\n",
    "            })\n",
    "    images_df = pd.DataFrame(images)\n",
    "    images_df.to_hdf(p_apply / f\"images_{ds_id}.hdf5\", key=\"df\")\n",
    "    print(f'Images for {ds_id} saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-saved individual images_df\n",
    "list_of_dfs = []\n",
    "for fpath in p_apply.rglob(\"*.hdf5\"):\n",
    "    print(f\"Loading {fpath.name}\")\n",
    "    f = pd.read_hdf(fpath)\n",
    "    list_of_dfs.append(f)\n",
    "    \n",
    "images_df = pd.concat(list_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:00.872379Z",
     "start_time": "2021-06-02T16:09:00.846905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wellmap and grids\n",
    "wellmap = pd.read_csv(p_wellmap)\n",
    "grids = {\n",
    "    ds_id: np.load(ds_p) \n",
    "    for ds_id, ds_p in zip(dataset_ids, dataset_paths)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:03.532632Z",
     "start_time": "2021-06-02T16:09:03.498051Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge images and metadata\n",
    "merged_df = (images_df.merge(wellmap[['well', 'formula', 'name_short']], on=['formula'])\n",
    ").reset_index()\n",
    "\n",
    "merged_df['score'] = np.nan\n",
    "merged_df['filename'] = [f'{row.formula}_{row.adduct}_{row.neutral_loss}_{row.well}_{row.dataset_id}.png' for row in merged_df.itertuples()]\n",
    "merged_df['row_id'] = [f'{row.formula}_{row.adduct}_{row.neutral_loss}_{row.well}_{row.dataset_id}' for row in merged_df.itertuples()]  # You may want to customize this and add any other fields you feel are necessary to uniquely identify a scored image+well\n",
    "merged_df = merged_df.set_index('row_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics (or load pre-calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:13.899106Z",
     "start_time": "2021-06-02T16:09:05.030910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "def calc_far_bg(mask, bg):\n",
    "    \"\"\"Gets mask for background pixels that are at least 4 radii away from the spot\"\"\"\n",
    "    # 3 iterations = (1+3=)4x the spot radius\n",
    "    expanded_spot = binary_dilation(mask, crop_zeros(mask), iterations=3)\n",
    "    return bg & ~expanded_spot\n",
    "\n",
    "def occ(px):\n",
    "    \"\"\"Calculates non-zero % of the given array\"\"\"\n",
    "    return np.count_nonzero(px) / px.size\n",
    "\n",
    "\n",
    "metrics = []\n",
    "for row in merged_df.itertuples():\n",
    "    grid = grids[row.dataset_id]\n",
    "    \n",
    "    mask = grid == row.well\n",
    "    bg = grid == 0\n",
    "    far_bg = calc_far_bg(mask, bg)\n",
    "        \n",
    "    in_mask = row.image[mask]   \n",
    "    in_bg = row.image[bg]\n",
    "    in_far_bg = row.image[far_bg]   \n",
    "    in_other_spots = row.image[~bg & ~mask]\n",
    "    \n",
    "    # tic image\n",
    "    in_mask_tic_norm = row.tic_norm_image[mask]\n",
    "    in_far_bg_tic = row.tic_norm_image[far_bg]\n",
    "    in_other_spots_tic = row.tic_norm_image[~bg & ~mask]\n",
    "    \n",
    "    # Calculate threshold (0.01 * 99th percentile) \n",
    "    # (note the image is already hotspot-removed, so the max is the 99th percentile)\n",
    "    threshold = np.max(row.image) * 0.01\n",
    "\n",
    "    metrics.append({\n",
    "        'row_id': row[0],   # with .itertuples(), item[0] is the index\n",
    "        # Original metrics\n",
    "        # NOTE: The constant in the denominator of `on_off_ratio` was changed to\n",
    "        # 0.001 as it seemed to produce slightly better results\n",
    "        'occupancy_ratio': (occ(in_mask) * 100) / (occ(in_bg) * 100 + 1),\n",
    "        'on_off_ratio': (np.mean(in_mask)) / (np.mean(in_bg) + 0.001),\n",
    "        \n",
    "        # Single-spot occupancy %\n",
    "        'spot_occupancy': occ(in_mask),\n",
    "        'spot_occupancy_thresholded': occ(in_mask > threshold),\n",
    "        # Other occupancy metrics\n",
    "        'image_occupancy': occ(row.image),\n",
    "        'other_spots_occupancy': occ(in_other_spots),\n",
    "        'bg_occupancy': occ(in_bg),\n",
    "        'far_bg_occupancy': occ(in_bg),\n",
    "        'occupancy_vs_far_bg_ratio' : (occ(in_mask) * 100) / (occ(in_far_bg) * 100 + 1),\n",
    "        \n",
    "        # How many spots have a non-zero pixel\n",
    "        'in_n_spots': len(np.unique(grid[(grid != 0) & (row.image > threshold)])),\n",
    "        \n",
    "        # Intensity ratios\n",
    "        'spot_intensity' : np.mean(in_mask),\n",
    "        'spot_intensity_tic_norm': np.mean(in_mask_tic_norm),\n",
    "        'spot_intensity_bgr_corrected' : np.mean(in_mask) - np.mean(in_far_bg),\n",
    "        'spot_intensity_sum' : np.sum(in_mask),\n",
    "        'spot_intensity_std' : np.std(in_mask),\n",
    "        'other_spot_intensity': np.mean(in_other_spots),\n",
    "        'bg_intensity' : np.mean(in_bg),\n",
    "        'far_bg_intensity' : np.mean(in_far_bg),\n",
    "        #Intensity ratios\n",
    "        'intensity_vs_far_bg_ratio': np.mean(in_mask) / (np.mean(in_far_bg) + 0.001),\n",
    "        'intensity_vs_other_spots_ratio': np.mean(in_mask) / (np.mean(in_other_spots) + 0.001),\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).set_index('row_id')\n",
    "metrics_df.to_csv(p_metrics)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Or import pre-calculated metrics\n",
    "# p_metrics = p_apply / \"metrics_08-Dec-2021.csv\"\n",
    "# metrics_df = pd.read_csv(p_metrics, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = metrics_df.merge(merged_df[['score']], left_index=True, right_index=True, how='left')\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pertrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:54:58.014519Z",
     "start_time": "2021-06-02T16:54:57.991621Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(verbose=False)\n",
    "features = ['spot_intensity_tic_norm', 'spot_occupancy', 'occupancy_vs_far_bg_ratio', 'intensity_vs_far_bg_ratio', 'intensity_vs_other_spots_ratio']\n",
    "\n",
    "model.load_model(p_model, format='json')\n",
    "\n",
    "# Make predictions for all data\n",
    "predictions_df = pd.DataFrame({\n",
    "    'pred_val': model.predict_proba(metrics_df[features].values)[:, 1]\n",
    "}, index=metrics_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign labels to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:47.130742Z",
     "start_time": "2021-06-02T16:58:47.104805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make combined DF\n",
    "output_df = merged_df.join(metrics_df.drop(columns='score')).join(predictions_df)\n",
    "\n",
    "# Add two-state and three-state classes\n",
    "output_df['pred_twostate'] = np.where(output_df.pred_val < 0.5, 0, 1)\n",
    "unsure_range = [0.2, 0.8] # Lowest & highest values to include in the \"unsure\" class\n",
    "# This assigns 0 = negative, 1 = unsure, 2 = positive\n",
    "output_df['pred_threestate'] = np.digitize(output_df.pred_val, unsure_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write predictions CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:48.369446Z",
     "start_time": "2021-06-02T16:58:48.294036Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_df = output_df.drop(columns=['image', 'tic_norm_image']) # Skip unwanted columns\n",
    "csv_df.to_csv(p_predictions)\n",
    "\n",
    "for dataset_id, results_df in csv_df.groupby('dataset_id'):\n",
    "    output_path = p_apply / f'{dataset_id}_predictions.csv'\n",
    "    results_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write image files into false positives, false negatives, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-02T16:58:53.453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean output directories\n",
    "for output_path in [\n",
    "    p_apply_fpos, p_apply_fneg, p_apply_tpos, p_apply_tneg, p_apply_upos, p_apply_uneg, \n",
    "    p_tri_pos, p_tri_unk, p_tri_neg\n",
    "]:\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    for f in output_path.glob('*.png'):\n",
    "        f.unlink()  # Delete existing files\n",
    "\n",
    "# Write images with two-state classification\n",
    "for row in output_df.itertuples():\n",
    "    mask = grids[row.dataset_id] == row.well\n",
    "    \n",
    "    # Figure out which directory to use\n",
    "    if row.score == 0:\n",
    "        twostate_path = [p_apply_tneg, p_apply_fpos][row.pred_twostate]\n",
    "    elif row.score == 1:\n",
    "        twostate_path = [p_apply_fneg, p_apply_tpos][row.pred_twostate]\n",
    "    else:\n",
    "        twostate_path = [p_apply_uneg, p_apply_upos][row.pred_twostate]\n",
    "        continue\n",
    "    \n",
    "    save_image_with_mask(row.image, mask, twostate_path / row.filename, row.tic_norm_image)\n",
    "    \n",
    "# Write images with three-state classification\n",
    "for row in output_df.itertuples():\n",
    "    mask = grids[row.dataset_id] == row.well\n",
    "    \n",
    "    threestate_path = [p_tri_neg, p_tri_unk, p_tri_pos][row.pred_threestate]\n",
    "    \n",
    "    save_image_with_mask(row.image, mask, threestate_path / row.filename, row.tic_norm_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curate predictions and make changes using change_to folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images for which prediction needs to be changed\n",
    "p_new_pos = p_apply / 'change_to_pos'\n",
    "p_new_unsure = p_apply / 'change_to_neg'\n",
    "p_new_neg = p_apply / 'change_to_unsure'\n",
    "\n",
    "changed_labels = []\n",
    "for score, labels_path in [(0.81, p_new_pos), (0.49, p_new_unsure), (0.01, p_new_neg)]:\n",
    "    labels_path.mkdir(parents=True, exist_ok=True)\n",
    "    for f in labels_path.glob('*.png'):\n",
    "        changed_labels.append({\n",
    "            'filename': f.name,\n",
    "            'pred_val_override': score,\n",
    "        })\n",
    "if changed_labels:\n",
    "    pred_override = pd.DataFrame(changed_labels)\n",
    "else:\n",
    "    pred_override = pd.DataFrame({'filename': pd.Series(dtype=str), 'pred_val_override': pd.Series(dtype='i')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update prediction values\n",
    "csv_df_curated = csv_df.merge(pred_override, on='filename', how='left') \n",
    "csv_df_curated['pred_val'] = csv_df_curated.pred_val_override.fillna(csv_df_curated.pred_val) \n",
    "\n",
    "# Add two-state and three-state classes\n",
    "csv_df_curated['pred_twostate'] = np.where(csv_df_curated.pred_val < 0.5, 0, 1)\n",
    "unsure_range = [0.2, 0.8] # Lowest & highest values to include in the \"unsure\" class\n",
    "# This assigns 0 = negative, 1 = unsure, 2 = positive\n",
    "csv_df_curated['pred_threestate'] = np.digitize(csv_df_curated.pred_val, unsure_range)\n",
    "\n",
    "csv_df_curated = csv_df_curated.drop(columns=['pred_val_override'])\n",
    "\n",
    "# Save as separate file \n",
    "csv_df_curated.to_csv(p_predictions_curated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
