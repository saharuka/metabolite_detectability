{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate classification models & dump images for diagnosis/labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:33.610129Z",
     "start_time": "2021-06-02T16:06:33.498927Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.264180Z",
     "start_time": "2021-06-02T16:06:33.940237Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.ndimage import binary_dilation\n",
    "from sklearn import clone\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from definitions import ROOT_DIR\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from metaspace.sm_annotation_utils import SMInstance\n",
    "from metaspace.image_processing import clip_hotspots\n",
    "\n",
    "import getpass\n",
    "from metaspace import SMInstance\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.285960Z",
     "start_time": "2021-06-02T16:06:34.265231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings, because many models spam them during feature selection\n",
    "# as some subsets of features just don't have enough information to make\n",
    "# a good model.\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.833722Z",
     "start_time": "2021-06-02T16:06:34.810682Z"
    }
   },
   "outputs": [],
   "source": [
    "def colorize_image_with_mask(image, mask):\n",
    "    \"\"\"Plotting function for combining a colorized ion image with a spot mask\"\"\"\n",
    "    image = clip_hotspots(image)\n",
    "    on_spot_colorized = plt.cm.cividis(image)\n",
    "    off_spot_colorized = plt.cm.magma(image)\n",
    "    return np.where(mask[:,:,np.newaxis], on_spot_colorized, off_spot_colorized)\n",
    "    \n",
    "def save_image_with_mask(image, mask, fname):\n",
    "    plt.imsave(fname, colorize_image_with_mask(image, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:35.191813Z",
     "start_time": "2021-06-02T16:06:35.170946Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_zeros(img):\n",
    "    \"\"\"Crop an image, removing all empty outer rows/columns\"\"\"\n",
    "    cols = np.flatnonzero(np.count_nonzero(img, axis=0) != 0)\n",
    "    rows = np.flatnonzero(np.count_nonzero(img, axis=1) != 0)\n",
    "    top = rows[0]\n",
    "    bottom = rows[-1] + 1\n",
    "    left = cols[0]\n",
    "    right = cols[-1] + 1\n",
    "\n",
    "    return img[top:bottom, left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:35.605701Z",
     "start_time": "2021-06-02T16:06:35.584102Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mispredictions(model, X, y):\n",
    "    \"\"\"\n",
    "    Find which values would be mispredicted, returning two lists:\n",
    "        * indexes of items that would be falsely predicted as positives\n",
    "        * indexes of items that would be falsely predicted as negatives\n",
    "        \n",
    "    cross_val_predict uses a shuffled 5-fold test-train split so that each chunk of \n",
    "    20% of the input data gets its own model that was trained on the other 80%, \n",
    "    ensuring that the items being predicted aren't included in the training data.\n",
    "    \"\"\"\n",
    "    preds = cross_val_predict(model, X, y)\n",
    "    mispreds = preds != y\n",
    "    fpos_idxs = np.flatnonzero(mispreds & ~y)\n",
    "    fneg_idxs = np.flatnonzero(mispreds & y)\n",
    "        \n",
    "    return fpos_idxs, fneg_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:36.849373Z",
     "start_time": "2021-06-02T16:06:36.826914Z"
    }
   },
   "outputs": [],
   "source": [
    "p_root_dir = Path(ROOT_DIR)\n",
    "# p_grids = p_root_dir / \"2_grid_calibration/grid_masks\"\n",
    "# p_wellmap = p_root_dir / \"3_metric_extraction/Well_2_compound.csv\"\n",
    "# p_stats = p_root_dir / \"4_metric_extension\"\n",
    "# p_analysis = p_root_dir  / \"5_well_classification\"\n",
    "# p_labelled_set = p_analysis / \"labelled_set\"\n",
    "# p_datasets = p_labelled_set / \"Datasets.csv\"\n",
    "\n",
    "p_analysis = p_root_dir  / \"4_model_evaluation\"\n",
    "p_grids = p_analysis / r\"data_for_model_training\\labelled_set_masks\\grid_masks\"\n",
    "p_labelled_set = p_analysis / r\"data_for_model_training\\labelled_set\"\n",
    "p_wellmap = p_root_dir / \"5_data_analysis/wellmap.csv\"\n",
    "p_metrics = p_analysis / \"metrics.csv\"\n",
    "\n",
    "# Paths for evaluation\n",
    "p_eval = p_analysis/ \"model_evaluation\"\n",
    "p_eval_preds = p_eval / 'predictions.csv'\n",
    "# False positives/negatives - preview output from model prediction for molecules with known labels\n",
    "# Note that all files in these directories are cleared before a prediction run\n",
    "p_eval_fpos = p_eval / 'false_positives'\n",
    "p_eval_fneg = p_eval / 'false_negatives'\n",
    "p_eval_tpos = p_eval / 'true_positives'\n",
    "p_eval_tneg = p_eval / 'true_negatives'\n",
    "# Unknown positives/negatives - preview output from model prediction for molecules with no label\n",
    "# Note that all files in these directories are cleared before a prediction run\n",
    "p_eval_upos = p_eval / 'unknown_positives'\n",
    "p_eval_uneg = p_eval / 'unknown_negatives'\n",
    "# Manually labeled positives/negatives - Move preview files from any of the above directories into \n",
    "# these directories to add to the labelled data. Make sure to re-run the appropriate steps \n",
    "# in \"Input data\" to detect the changes\n",
    "p_eval_lpos = p_eval / 'manual_label_positives'\n",
    "p_eval_lneg = p_eval / 'manual_label_negatives'\n",
    "\n",
    "# Directories for three-state positive/unsure/negative classification\n",
    "p_tri_pos = p_eval / 'three-state' / 'positive'\n",
    "p_tri_unk = p_eval / 'three-state' / 'unsure'\n",
    "p_tri_neg = p_eval / 'three-state' / 'negative'\n",
    "\n",
    "\n",
    "# METASPACE\n",
    "database = ('Spotting_project_compounds-v9', 'feb2021')\n",
    "fdr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key: ········\n"
     ]
    }
   ],
   "source": [
    "# Log into metaspace\n",
    "sm = SMInstance(host='https://metaspace2020.eu')\n",
    "\n",
    "if not sm.logged_in():\n",
    "    # Using getpass here prevents the API key from being accidentally saved with this notebook.\n",
    "    api_key = getpass.getpass(prompt='API key: ', stream=None)\n",
    "    sm.login(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:38.160316Z",
     "start_time": "2021-06-02T16:06:38.112047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dataset IDs based on Quality_Labels.csv files \n",
    "dataset_ids = pd.concat([\n",
    "    pd.read_csv(f)\n",
    "    for f in p_labelled_set.rglob(\"*Quality_Labels.csv\")\n",
    "]).dataset_id.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:08:50.018554Z",
     "start_time": "2021-06-02T16:06:38.808059Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images for 2021-02-15_17h57m16s (0/14)\n",
      "Downloading images for 2021-02-16_06h28m34s (1/14)\n",
      "Downloading images for 2021-02-17_18h14m40s (2/14)\n",
      "Downloading images for 2021-02-19_12h11m04s (3/14)\n",
      "Downloading images for 2021-02-28_07h58m29s (4/14)\n",
      "Downloading images for 2021-03-05_15h01m51s (5/14)\n",
      "Downloading images for 2021-03-07_11h36m10s (6/14)\n",
      "Downloading images for 2021-03-08_10h38m53s (7/14)\n",
      "Downloading images for 2021-03-24_21h05m49s (8/14)\n",
      "Downloading images for 2021-03-24_23h18m35s (9/14)\n",
      "Downloading images for 2021-04-11_21h47m45s (10/14)\n",
      "Downloading images for 2021-04-11_21h56m24s (11/14)\n",
      "Downloading images for 2021-04-26_15h41m55s (12/14)\n",
      "Downloading images for 2021-04-26_16h00m28s (13/14)\n"
     ]
    }
   ],
   "source": [
    "# Images from METASPACE\n",
    "# NOTE: Hotspot clipping is applied at this step, so `np.max(image)` \n",
    "# represents the 99th percentile intensity for the rest of the script.\n",
    "#\n",
    "# Ignore any warnings about connection pools in this step\n",
    "\n",
    "images = []\n",
    "for i, ds_id in enumerate(dataset_ids):\n",
    "    print(f'Downloading images for {ds_id} ({i}/{len(dataset_ids)})')\n",
    "    for img in sm.dataset(id=ds_id).all_annotation_images(\n",
    "        fdr=fdr, \n",
    "        database=database, \n",
    "        only_first_isotope=True, \n",
    "        scale_intensity=False, \n",
    "        hotspot_clipping=True\n",
    "    ):\n",
    "        # Exclude annotations with no first-isotopic-image\n",
    "        if img[0] is not None:\n",
    "            images.append({\n",
    "                'dataset_id': ds_id,\n",
    "                'formula': img.formula,\n",
    "                'adduct': img.adduct,\n",
    "                'neutral_loss': img.neutral_loss or '',\n",
    "                'image': img[0],\n",
    "                'filename': f'{ds_id}_{img.formula}_{img.adduct}_{img.neutral_loss}.png'.replace('+', ''),\n",
    "            })\n",
    "\n",
    "images_df = pd.DataFrame(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:00.872379Z",
     "start_time": "2021-06-02T16:09:00.846905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wellmap and grids\n",
    "wellmap = pd.read_csv(p_wellmap)\n",
    "grids = {\n",
    "    ds_id: np.load(p_grids / f'{ds_id}.npy') \n",
    "    for ds_id in dataset_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:01.342997Z",
     "start_time": "2021-06-02T16:09:01.288020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image labels from Quality_Labels.csv files\n",
    "labeled_anns = []\n",
    "for i in p_labelled_set.rglob(\"*Quality_Labels.csv\"):\n",
    "    data = pd.read_csv(i)\n",
    "    data = data.loc[:, ['dataset_id', 'formula', 'adduct', 'neutral_loss', 'score']]\n",
    "    data.neutral_loss.fillna('', inplace=True)\n",
    "    labeled_anns.append(data)\n",
    "\n",
    "labeled_anns_df = pd.concat(labeled_anns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import image labels from the manual_label directories\n",
    "\n",
    "If you use these directories for labelling, re-run every cell from this point onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:02.819503Z",
     "start_time": "2021-06-02T16:09:02.794776Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image labels from the \"manual_label\" directories\n",
    "manual_labels = []\n",
    "for score, labels_path in [(1, p_eval_lpos), (0, p_eval_lneg)]:\n",
    "    labels_path.mkdir(parents=True, exist_ok=True)\n",
    "    for f in labels_path.glob('*.png'):\n",
    "        manual_labels.append({\n",
    "            'filename': f.name,\n",
    "            'manual_score': score,\n",
    "        })\n",
    "if manual_labels:\n",
    "    manual_labels_df = pd.DataFrame(manual_labels)\n",
    "else:\n",
    "    manual_labels_df = pd.DataFrame({'filename': pd.Series(dtype=str), 'manual_score': pd.Series(dtype='i')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:03.532632Z",
     "start_time": "2021-06-02T16:09:03.498051Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine them for easier access\n",
    "merged_df = (\n",
    "    images_df\n",
    "    # Add `how=left` when merging with wellmap to include non-spotted formulas\n",
    "    .merge(wellmap[['well', 'formula', 'name_short']], on=['formula'])\n",
    "    .merge(labeled_anns_df, on=['dataset_id', 'formula', 'adduct', 'neutral_loss'], how='left')\n",
    "    .merge(manual_labels_df, on='filename', how='left')\n",
    ").reset_index()\n",
    "\n",
    "# Merge the \"manual_score\" column into \"score\"\n",
    "merged_df['score'] = np.where(merged_df.score.isna(), merged_df.manual_score, merged_df.score)\n",
    "del merged_df['manual_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics (or load pre-calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:13.899106Z",
     "start_time": "2021-06-02T16:09:05.030910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupancy_ratio</th>\n",
       "      <th>on_off_ratio</th>\n",
       "      <th>spot_occupancy</th>\n",
       "      <th>spot_occupancy_thresholded</th>\n",
       "      <th>image_occupancy</th>\n",
       "      <th>other_spots_occupancy</th>\n",
       "      <th>bg_occupancy</th>\n",
       "      <th>far_bg_occupancy</th>\n",
       "      <th>occupancy_vs_far_bg_ratio</th>\n",
       "      <th>in_n_spots</th>\n",
       "      <th>spot_intensity</th>\n",
       "      <th>intensity_vs_other_spots_ratio</th>\n",
       "      <th>intensity_vs_far_bg_ratio</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.846154</td>\n",
       "      <td>55.776898</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.846154</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055777</td>\n",
       "      <td>55.535919</td>\n",
       "      <td>55.776898</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.846154</td>\n",
       "      <td>89.592762</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.846154</td>\n",
       "      <td>4</td>\n",
       "      <td>0.089593</td>\n",
       "      <td>88.844338</td>\n",
       "      <td>89.592762</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.749543</td>\n",
       "      <td>27.731240</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5.749220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>27.792176</td>\n",
       "      <td>27.730237</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.555635</td>\n",
       "      <td>244.620623</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>85.875339</td>\n",
       "      <td>2</td>\n",
       "      <td>0.249697</td>\n",
       "      <td>245.142977</td>\n",
       "      <td>249.578850</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.545055</td>\n",
       "      <td>198.311360</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>79.386183</td>\n",
       "      <td>4</td>\n",
       "      <td>0.201555</td>\n",
       "      <td>196.619429</td>\n",
       "      <td>201.086837</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   occupancy_ratio  on_off_ratio  spot_occupancy  spot_occupancy_thresholded  \\\n",
       "0        28.846154     55.776898        0.288462                    0.230769   \n",
       "1        28.846154     89.592762        0.288462                    0.269231   \n",
       "2         5.749543     27.731240        0.057692                    0.057692   \n",
       "3        83.555635    244.620623        0.864865                    0.810811   \n",
       "4        77.545055    198.311360        0.810811                    0.810811   \n",
       "\n",
       "   image_occupancy  other_spots_occupancy  bg_occupancy  far_bg_occupancy  \\\n",
       "0         0.000487               0.000409      0.000000          0.000000   \n",
       "1         0.000487               0.000409      0.000000          0.000000   \n",
       "2         0.000102               0.000000      0.000034          0.000034   \n",
       "3         0.001634               0.002304      0.000351          0.000351   \n",
       "4         0.001465               0.001296      0.000456          0.000456   \n",
       "\n",
       "   occupancy_vs_far_bg_ratio  in_n_spots  spot_intensity  \\\n",
       "0                  28.846154           2        0.055777   \n",
       "1                  28.846154           4        0.089593   \n",
       "2                   5.749220           1        0.027792   \n",
       "3                  85.875339           2        0.249697   \n",
       "4                  79.386183           4        0.201555   \n",
       "\n",
       "   intensity_vs_other_spots_ratio  intensity_vs_far_bg_ratio  score  \n",
       "0                       55.535919                  55.776898    NaN  \n",
       "1                       88.844338                  89.592762    NaN  \n",
       "2                       27.792176                  27.730237    NaN  \n",
       "3                      245.142977                 249.578850    NaN  \n",
       "4                      196.619429                 201.086837    NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate metrics\n",
    "def calc_far_bg(mask, bg):\n",
    "    \"\"\"Gets mask for background pixels that are at least 4 radii away from the spot\"\"\"\n",
    "    # 3 iterations = (1+3=)4x the spot radius\n",
    "    expanded_spot = binary_dilation(mask, crop_zeros(mask), iterations=3)\n",
    "    return bg & ~expanded_spot\n",
    "\n",
    "def occ(px):\n",
    "    \"\"\"Calculates non-zero % of the given array\"\"\"\n",
    "    return np.count_nonzero(px) / px.size\n",
    "\n",
    "\n",
    "metrics = []\n",
    "for row in merged_df.itertuples():\n",
    "    grid = grids[row.dataset_id]\n",
    "    \n",
    "    mask = grid == row.well\n",
    "    bg = grid == 0\n",
    "    far_bg = calc_far_bg(mask, bg)\n",
    "        \n",
    "    in_mask = row.image[mask]\n",
    "    in_bg = row.image[bg]\n",
    "    in_far_bg = row.image[far_bg]\n",
    "    in_other_spots = row.image[~bg & ~mask]\n",
    "    \n",
    "    # Calculate threshold (0.01 * 99th percentile) \n",
    "    # (note the image is already hotspot-removed, so the max is the 99th percentile)\n",
    "    threshold = np.max(row.image) * 0.01\n",
    "\n",
    "    metrics.append({\n",
    "        # Original metrics\n",
    "        # NOTE: The constant in the denominator of `on_off_ratio` was changed to\n",
    "        # 0.001 as it seemed to produce slightly better results\n",
    "        'occupancy_ratio': (occ(in_mask) * 100) / (occ(in_bg) * 100 + 1),\n",
    "        'on_off_ratio': (np.mean(in_mask)) / (np.mean(in_bg) + 0.001),\n",
    "        \n",
    "        # Single-spot occupancy %\n",
    "        'spot_occupancy': occ(in_mask),\n",
    "        'spot_occupancy_thresholded': occ(in_mask > threshold),\n",
    "        # Other occupancy metrics\n",
    "        'image_occupancy': occ(row.image),\n",
    "        'other_spots_occupancy': occ(in_other_spots),\n",
    "        'bg_occupancy': occ(in_bg),\n",
    "        'far_bg_occupancy': occ(in_bg),\n",
    "        'occupancy_vs_far_bg_ratio' : (occ(in_mask) * 100) / (occ(in_far_bg) * 100 + 1),\n",
    "        \n",
    "        \n",
    "        # How many spots have a non-zero pixel\n",
    "        'in_n_spots': len(np.unique(grid[(grid != 0) & (row.image > threshold)])),\n",
    "        \n",
    "        # Intensity ratios\n",
    "        'spot_intensity' : np.mean(in_mask),\n",
    "        'intensity_vs_other_spots_ratio': np.mean(in_mask) / (np.mean(in_other_spots) + 0.001),\n",
    "        'intensity_vs_far_bg_ratio': np.mean(in_mask) / (np.mean(in_far_bg) + 0.001),\n",
    "        \n",
    "        'score': row.score,\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=merged_df.index)\n",
    "metrics_df.to_csv(p_metrics, index=False)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('d:/saharuka/spotting/20_matrices_git/spotting/analysis/20_matrices/4_model_evaluation/metrics.csv')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or import pre-calculated metrics\n",
    "metrics_df = pd.read_csv(p_metrics)\n",
    "metrics_df['score'] = merged_df.score\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models\n",
    "\n",
    "This section uses the calculated metrics and labeled data to train a set of models \n",
    "and find which features are best for predicting the labels. \n",
    "It uses two strategies for evaluation:\n",
    "\n",
    "* Hold-out validation - this splits the labeled data into 80% for training, 20% for testing\n",
    "* Cross-Validation - this uses the full labeled data, but trains 5 different models, each\n",
    "    with a different combinations of inputs in the 80% training set, so that each input \n",
    "    can be tested by a model that didn't use that input as part of the training.\n",
    "    This approach reports a much more numerically stable accuracy value it can use \n",
    "    the full input set for evaluation.\n",
    "    However, it shouldn't be used for fine-tuning the model hyperparameters \n",
    "    (the input variables when constructing the model), as this can lead to overfitting.\n",
    "    \n",
    "   \n",
    "The output is a DataFrame `eval_results_df` that shows for each model/# of features:\n",
    "* Which combination of features worked best\n",
    "* The accuracy/F1 scores\n",
    "* The # of false positives & false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:16.020437Z",
     "start_time": "2021-06-02T16:09:15.995812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare input data\n",
    "input_df = metrics_df[~metrics_df.score.isna()]  # Exclude unlabeled rows\n",
    "input_df = input_df.sample(frac=1.0)  # Shuffle rows\n",
    "X = input_df.drop(columns=['score'])\n",
    "y = input_df.score.astype('i').values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:14:59.114845Z",
     "start_time": "2021-06-02T16:09:16.668321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostClassifier object at 0x000001D4ABD7C490> 1\n",
      "<catboost.core.CatBoostClassifier object at 0x000001D4ABD7C490> 2\n",
      "<catboost.core.CatBoostClassifier object at 0x000001D4ABD7C490> 3\n",
      "<catboost.core.CatBoostClassifier object at 0x000001D4ABD7C490> 4\n",
      "<catboost.core.CatBoostClassifier object at 0x000001D4ABD7C490> 5\n"
     ]
    }
   ],
   "source": [
    "# Models to try\n",
    "models_to_eval = [\n",
    "    CatBoostClassifier(verbose=False),\n",
    "    LinearSVC(class_weight='balanced'),\n",
    "    DecisionTreeClassifier(max_depth=3),\n",
    "    BaggingClassifier(LinearSVC(), n_estimators=3, bootstrap_features=True),\n",
    "]\n",
    "max_features_to_consider = 5\n",
    "\n",
    "eval_results = []\n",
    "\n",
    "for model in models_to_eval:\n",
    "    model_name = str(model)\n",
    "    for n_features in range(1, max_features_to_consider + 1):\n",
    "        print(model_name, n_features)\n",
    "        # SequentialFeatureSelector finds the set of N features that give the best scores\n",
    "        sfs = SequentialFeatureSelector(model, n_features_to_select=n_features, n_jobs=-1)\n",
    "        sfs.fit(X_train, y_train)\n",
    "        best_features = X.columns[sfs.support_]\n",
    "        \n",
    "        # Evaluate using cross-validation\n",
    "        X_subset = X[best_features].values\n",
    "        fpos_idxs, fneg_idxs = get_mispredictions(model, X_subset, y)\n",
    "        # Use a repeating cross-validator so that results are averaged over ~50 runs\n",
    "        cv = RepeatedStratifiedKFold()\n",
    "        cv_scores = cross_validate(model, X_subset, y, cv=cv, scoring=['accuracy','f1'])\n",
    "        cv_accuracy = np.mean(cv_scores['test_accuracy'])\n",
    "        cv_f1 = np.mean(cv_scores['test_f1'])\n",
    "        \n",
    "        # Evaluate using hold-out validation\n",
    "        trained_subset_model = clone(model).fit(X_train[best_features].values, y_train)\n",
    "        holdout_accuracy = trained_subset_model.score(X_test[best_features].values, y_test)\n",
    "        holdout_f1 = f1_score(y_test, trained_subset_model.predict(X_test[best_features].values))\n",
    "        \n",
    "        eval_results.append({\n",
    "            'model': model_name,\n",
    "            'n_features': n_features,\n",
    "            'features': ', '.join(best_features),\n",
    "            'cv_accuracy': cv_accuracy,\n",
    "            'cv_f1': cv_f1,\n",
    "            'holdout_accuracy': holdout_accuracy,\n",
    "            'holdout_f1': holdout_f1,\n",
    "            'n_fpos': len(fpos_idxs),\n",
    "            'n_fneg': len(fneg_idxs),\n",
    "            # Uncomment to include the idxs of false positives/negatives to see which\n",
    "            # inputs are repeatedly mispredicted regardless of the model\n",
    "            # 'fpos_idxs': fpos_idxs,\n",
    "            # 'fneg_idxs': fneg_idxs,\n",
    "        })\n",
    "        \n",
    "eval_results_df = pd.DataFrame(eval_results)\n",
    "\n",
    "eval_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:22:29.917816Z",
     "start_time": "2021-06-02T16:22:29.830719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show behavior of accuracy as number of features increases\n",
    "sns.lineplot(data=eval_results_df, x='n_features', y='cv_accuracy', hue='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results for a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:54:58.014519Z",
     "start_time": "2021-06-02T16:54:57.991621Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(verbose=False)\n",
    "# features = ['occupancy_ratio', 'intensity_vs_other_spots_ratio', 'spot_occupancy', 'spot_occupancy_thresholded'] #original\n",
    "features = ['spot_occupancy_thresholded', 'occupancy_vs_far_bg_ratio', 'intensity_vs_far_bg_ratio', 'intensity_vs_other_spots_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:29.785376Z",
     "start_time": "2021-06-02T16:58:26.677693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model on labeled data\n",
    "train_df = metrics_df[~metrics_df.score.isna()]  # Exclude unlabeled rows\n",
    "train_df = input_df.sample(frac=1.0)  # Shuffle rows\n",
    "X_df = train_df.drop(columns=['score'])[features]\n",
    "y = train_df.score.astype('i').values\n",
    "trained_model = clone(model).fit(X_df.values, y)\n",
    "\n",
    "# Make predictions for unlabeled data\n",
    "unlabeled_df = metrics_df[metrics_df.score.isna()][features]\n",
    "unlabeled_predictions_df = pd.DataFrame({\n",
    "    'pred_val': trained_model.predict_proba(unlabeled_df.values)[:, 1]\n",
    "}, index=unlabeled_df.index)\n",
    "\n",
    "# Make cross-validated predictions for labeled data\n",
    "labeled_predictions_df = pd.DataFrame({\n",
    "    'pred_val': cross_val_predict(model, X_df.values, y, method='predict_proba')[:, 1]\n",
    "}, index=X_df.index)\n",
    "\n",
    "# Combine predictions\n",
    "predictions_df = pd.concat([unlabeled_predictions_df, labeled_predictions_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Load an existing model\n",
    "Uses a saved model from the last step of this file\n",
    "\n",
    "NOTE: This approach doesn't use cross-validated predictions for the labelled training data,\n",
    "so it shouldn't be used for analyzing the model or refining the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T15:54:16.477074Z",
     "start_time": "2021-06-02T15:53:05.276Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_model(p_eval / 'model.json', format='json')\n",
    "\n",
    "# Make predictions for all data\n",
    "predictions_df = pd.DataFrame({\n",
    "    'pred_val': model.predict_proba(metrics_df[features].values)[:, 1]\n",
    "}, index=metrics_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both options: Assign labels to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:47.130742Z",
     "start_time": "2021-06-02T16:58:47.104805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make combined DF\n",
    "output_df = merged_df.join(metrics_df.drop(columns='score')).join(predictions_df)\n",
    "\n",
    "# Add two-state and three-state classes\n",
    "output_df['pred_twostate'] = np.where(output_df.pred_val < 0.5, 0, 1)\n",
    "unsure_range = [0.2, 0.8] # Lowest & highest values to include in the \"unsure\" class\n",
    "# This assigns 0 = negative, 1 = unsure, 2 = positive\n",
    "output_df['pred_threestate'] = np.digitize(output_df.pred_val, unsure_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write predictions CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:48.369446Z",
     "start_time": "2021-06-02T16:58:48.294036Z"
    }
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%d-%b-%Y\") \n",
    "csv_df = output_df.drop(columns=['image', 'filename']) # Skip unwanted columns\n",
    "csv_df.to_csv(p_root_dir / f\"5_data_analysis/all_predictions_{timestamp}.csv\")\n",
    "\n",
    "for dataset_id, results_df in csv_df.groupby('dataset_id'):\n",
    "    output_path = p_eval / f'{dataset_id}_predictions.csv'\n",
    "    results_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write image files into false positives, false negatives, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-02T16:58:53.453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean output directories\n",
    "for output_path in [\n",
    "    p_eval_fpos, p_eval_fneg, p_eval_tpos, p_eval_tneg, p_eval_upos, p_eval_uneg, \n",
    "    p_tri_pos, p_tri_unk, p_tri_neg\n",
    "]:\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    for f in output_path.glob('*.png'):\n",
    "        f.unlink()  # Delete existing files\n",
    "\n",
    "# Write images with two-state classification\n",
    "for row in output_df.itertuples():\n",
    "    mask = grids[row.dataset_id] == row.well\n",
    "    \n",
    "    # Figure out which directory to use\n",
    "    if row.score == 0:\n",
    "        twostate_path = [p_eval_tneg, p_eval_fpos][row.pred_twostate]\n",
    "    elif row.score == 1:\n",
    "        twostate_path = [p_eval_fneg, p_eval_tpos][row.pred_twostate]\n",
    "    else:\n",
    "        twostate_path = [p_eval_uneg, p_eval_upos][row.pred_twostate]\n",
    "    \n",
    "    save_image_with_mask(row.image, mask, twostate_path / row.filename)\n",
    "    \n",
    "# Write images with three-state classification\n",
    "for row in output_df.itertuples():\n",
    "    mask = grids[row.dataset_id] == row.well\n",
    "    \n",
    "    threestate_path = [p_tri_neg, p_tri_unk, p_tri_pos][row.pred_threestate]\n",
    "    \n",
    "    save_image_with_mask(row.image, mask, threestate_path / row.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained model\n",
    "\n",
    "Note: This JSON export only works for CatBoost. \n",
    "scikit-learn models don't have a standardized export format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-02T16:59:12.221Z"
    }
   },
   "outputs": [],
   "source": [
    "trained_model.save_model(p_eval / 'model.json', format='json', pool=Pool(X_df.values, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
