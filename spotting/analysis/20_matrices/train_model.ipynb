{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate classification models & dump images for diagnosis/labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:33.610129Z",
     "start_time": "2021-06-02T16:06:33.498927Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.264180Z",
     "start_time": "2021-06-02T16:06:33.940237Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.ndimage import binary_dilation\n",
    "from sklearn import clone\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from definitions import ROOT_DIR\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from metaspace.sm_annotation_utils import SMInstance\n",
    "from metaspace.image_processing import clip_hotspots\n",
    "\n",
    "import getpass\n",
    "from metaspace import SMInstance\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.285960Z",
     "start_time": "2021-06-02T16:06:34.265231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings, because many models spam them during feature selection\n",
    "# as some subsets of features just don't have enough information to make\n",
    "# a good model.\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:34.833722Z",
     "start_time": "2021-06-02T16:06:34.810682Z"
    }
   },
   "outputs": [],
   "source": [
    "def colorize_image_with_mask(image, mask):\n",
    "    \"\"\"Plotting function for combining a colorized ion image with a spot mask\"\"\"\n",
    "    \n",
    "    image = clip_hotspots(image)\n",
    "    image /= np.max(image)\n",
    "    \n",
    "    on_spot_colorized = plt.cm.cividis(image)\n",
    "    off_spot_colorized = plt.cm.magma(image)\n",
    "    return np.where(mask[:,:,np.newaxis], on_spot_colorized, off_spot_colorized)\n",
    "    \n",
    "def save_image_with_mask(image, mask, fname):\n",
    "    plt.imsave(fname, colorize_image_with_mask(image, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:35.191813Z",
     "start_time": "2021-06-02T16:06:35.170946Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_zeros(img):\n",
    "    \"\"\"Crop an image, removing all empty outer rows/columns\"\"\"\n",
    "    cols = np.flatnonzero(np.count_nonzero(img, axis=0) != 0)\n",
    "    rows = np.flatnonzero(np.count_nonzero(img, axis=1) != 0)\n",
    "    top = rows[0]\n",
    "    bottom = rows[-1] + 1\n",
    "    left = cols[0]\n",
    "    right = cols[-1] + 1\n",
    "\n",
    "    return img[top:bottom, left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:35.605701Z",
     "start_time": "2021-06-02T16:06:35.584102Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mispredictions(model, X, y):\n",
    "    \"\"\"\n",
    "    Find which values would be mispredicted, returning two lists:\n",
    "        * indexes of items that would be falsely predicted as positives\n",
    "        * indexes of items that would be falsely predicted as negatives\n",
    "        \n",
    "    cross_val_predict uses a shuffled 5-fold test-train split so that each chunk of \n",
    "    20% of the input data gets its own model that was trained on the other 80%, \n",
    "    ensuring that the items being predicted aren't included in the training data.\n",
    "    \"\"\"\n",
    "    preds = cross_val_predict(model, X, y)\n",
    "    mispreds = preds != y\n",
    "    fpos_idxs = np.flatnonzero(mispreds & ~y)\n",
    "    fneg_idxs = np.flatnonzero(mispreds & y)\n",
    "        \n",
    "    return fpos_idxs, fneg_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:36.849373Z",
     "start_time": "2021-06-02T16:06:36.826914Z"
    }
   },
   "outputs": [],
   "source": [
    "p_root_dir = Path(ROOT_DIR)\n",
    "p_analysis = p_root_dir  / \"4_model_evaluation\"\n",
    "p_grids = p_analysis / r\"data_for_model_training\\labelled_set_masks\\grid_masks\"\n",
    "p_labelled_set = p_analysis / r\"data_for_model_training\\labelled_set\"\n",
    "p_wellmap = p_root_dir / \"5_data_analysis/wellmap.csv\"\n",
    "\n",
    "# Paths for evaluation\n",
    "p_eval = p_analysis/ \"model_evaluation\"\n",
    "p_metrics = p_eval / \"metrics.csv\"\n",
    "p_images = p_eval / \"images.hdf5\"\n",
    "p_model = p_eval / \"model.json\"\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%d-%b-%Y\") \n",
    "p_predictions = p_eval / f\"labelles_set_predictions_{timestamp}.csv\"\n",
    "\n",
    "# False positives/negatives - preview output from model prediction for molecules with known labels\n",
    "# Note that all files in these directories are cleared before a prediction run\n",
    "p_eval_fpos = p_eval / 'false_positives'\n",
    "p_eval_fneg = p_eval / 'false_negatives'\n",
    "p_eval_tpos = p_eval / 'true_positives'\n",
    "p_eval_tneg = p_eval / 'true_negatives'\n",
    "# Unknown positives/negatives - preview output from model prediction for molecules with no label\n",
    "# Note that all files in these directories are cleared before a prediction run\n",
    "p_eval_upos = p_eval / 'unknown_positives'\n",
    "p_eval_uneg = p_eval / 'unknown_negatives'\n",
    "# Manually labeled positives/negatives - Move preview files from any of the above directories into \n",
    "# these directories to add to the labelled data. Make sure to re-run the appropriate steps \n",
    "# in \"Input data\" to detect the changes\n",
    "p_eval_lpos = p_eval / 'manual_label_positives'\n",
    "p_eval_lneg = p_eval / 'manual_label_negatives'\n",
    "\n",
    "# Directories for three-state positive/unsure/negative classification\n",
    "p_tri_pos = p_eval / 'three-state' / 'positive'\n",
    "p_tri_unk = p_eval / 'three-state' / 'unsure'\n",
    "p_tri_neg = p_eval / 'three-state' / 'negative'\n",
    "\n",
    "\n",
    "# METASPACE\n",
    "database = ('Spotting_project_compounds-v9', 'feb2021')\n",
    "fdr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key: ········\n"
     ]
    }
   ],
   "source": [
    "# Log into metaspace\n",
    "sm = SMInstance(host='https://metaspace2020.eu')\n",
    "\n",
    "if not sm.logged_in():\n",
    "    # Using getpass here prevents the API key from being accidentally saved with this notebook.\n",
    "    api_key = getpass.getpass(prompt='API key: ', stream=None)\n",
    "    sm.login(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:06:38.160316Z",
     "start_time": "2021-06-02T16:06:38.112047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dataset IDs based on Quality_Labels.csv files \n",
    "dataset_ids = pd.concat([\n",
    "    pd.read_csv(f)\n",
    "    for f in p_labelled_set.rglob(\"*Quality_Labels.csv\")\n",
    "]).dataset_id.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download images from metaspace or load them in if they were pre-saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:08:50.018554Z",
     "start_time": "2021-06-02T16:06:38.808059Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images for 2021-02-15_17h57m16s (0/14)\n",
      "Downloading images for 2021-02-16_06h28m34s (1/14)\n",
      "Downloading images for 2021-02-17_18h14m40s (2/14)\n",
      "Downloading images for 2021-02-19_12h11m04s (3/14)\n",
      "Downloading images for 2021-02-28_07h58m29s (4/14)\n",
      "Downloading images for 2021-03-05_15h01m51s (5/14)\n",
      "Downloading images for 2021-03-07_11h36m10s (6/14)\n",
      "Downloading images for 2021-03-08_10h38m53s (7/14)\n",
      "Downloading images for 2021-03-24_21h05m49s (8/14)\n",
      "Downloading images for 2021-03-24_23h18m35s (9/14)\n",
      "Downloading images for 2021-04-11_21h47m45s (10/14)\n",
      "Downloading images for 2021-04-11_21h56m24s (11/14)\n",
      "Downloading images for 2021-04-26_15h41m55s (12/14)\n",
      "Downloading images for 2021-04-26_16h00m28s (13/14)\n"
     ]
    }
   ],
   "source": [
    "# Download images from METASPACE\n",
    "# Ignore any warnings about connection pools in this step\n",
    "\n",
    "images = []\n",
    "for i, ds_id in enumerate(dataset_ids):\n",
    "    print(f'Downloading images for {ds_id} ({i}/{len(dataset_ids)})')\n",
    "    dataset = sm.dataset(id=ds_id)\n",
    "    ds_tic_image = dataset.tic_image()\n",
    "    for img in dataset.all_annotation_images(\n",
    "        fdr=fdr, \n",
    "        database=database, \n",
    "        only_first_isotope=True, \n",
    "        scale_intensity=True, \n",
    "        hotspot_clipping=False\n",
    "    ):\n",
    "        # Exclude annotations with no first-isotopic-image\n",
    "        if img[0] is not None:\n",
    "            images.append({\n",
    "                'dataset_id': ds_id,\n",
    "                'formula': img.formula,\n",
    "                'adduct': img.adduct,\n",
    "                'neutral_loss': img.neutral_loss or '',\n",
    "                'image': img[0],\n",
    "                'tic_norm_image': np.nan_to_num(img[0] / ds_tic_image),  # nan_to_num replaces nan values with 0.0. This line will probably complain about division by zero but it can be ignored as it's fixed by the nan_to_num\n",
    "            })\n",
    "\n",
    "images_df = pd.DataFrame(images)\n",
    "p_eval.mkdir(parents=True, exist_ok=True)\n",
    "images_df.to_hdf(p_images, key=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or load pre-saved images\n",
    "images_df = pd.read_hdf(p_eval / \"images.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:00.872379Z",
     "start_time": "2021-06-02T16:09:00.846905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wellmap and grids\n",
    "wellmap = pd.read_csv(p_wellmap)\n",
    "grids = {\n",
    "    ds_id: np.load(p_grids / f'{ds_id}.npy') \n",
    "    for ds_id in dataset_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:01.342997Z",
     "start_time": "2021-06-02T16:09:01.288020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image labels from Quality_Labels.csv files\n",
    "labeled_anns = []\n",
    "for i in p_labelled_set.rglob(\"*Quality_Labels.csv\"):\n",
    "    data = pd.read_csv(i)\n",
    "    data = data.loc[:, ['dataset_id', 'formula', 'adduct', 'neutral_loss', 'score', 'well']]\n",
    "    data.neutral_loss.fillna('', inplace=True)\n",
    "    labeled_anns.append(data)\n",
    "\n",
    "labeled_anns_df = pd.concat(labeled_anns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import image labels from the manual_label directories\n",
    "\n",
    "If you use these directories for labelling, re-run every cell from this point onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:02.819503Z",
     "start_time": "2021-06-02T16:09:02.794776Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image labels from the \"manual_label\" directories\n",
    "manual_labels = []\n",
    "for score, labels_path in [(1, p_eval_lpos), (0, p_eval_lneg)]:\n",
    "    labels_path.mkdir(parents=True, exist_ok=True)\n",
    "    for f in labels_path.glob('*.png'):\n",
    "        manual_labels.append({\n",
    "            'filename': f.name,\n",
    "            'manual_score': score,\n",
    "        })\n",
    "if manual_labels:\n",
    "    manual_labels_df = pd.DataFrame(manual_labels)\n",
    "else:\n",
    "    manual_labels_df = pd.DataFrame({'filename': pd.Series(dtype=str), 'manual_score': pd.Series(dtype='i')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:03.532632Z",
     "start_time": "2021-06-02T16:09:03.498051Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine them for easier access\n",
    "merged_df = (\n",
    "    images_df\n",
    "    # Add `how=left` when merging with wellmap to include non-spotted formulas\n",
    "    .merge(wellmap[['well', 'formula', 'name_short']], on=['formula'])\n",
    "    .merge(labeled_anns_df, on=['dataset_id', 'formula', 'adduct', 'neutral_loss', 'well'], how='left')\n",
    ").reset_index()\n",
    "\n",
    "merged_df['filename'] = [f'{row.dataset_id}_{row.formula}_{row.adduct}_{row.neutral_loss}_{row.well}.png' for row in merged_df.itertuples()]\n",
    "merged_df = merged_df.merge(manual_labels_df, on='filename', how='left')\n",
    "\n",
    "# Merge the \"manual_score\" column into \"score\"\n",
    "merged_df['score'] = merged_df.manual_score.fillna(merged_df.score) # manual labels overwrite csv labels\n",
    "del merged_df['manual_score']\n",
    "\n",
    "merged_df['row_id'] = [f'{row.dataset_id}_{row.formula}_{row.adduct}_{row.neutral_loss}_{row.well}' for row in merged_df.itertuples()]  # You may want to customize this and add any other fields you feel are necessary to uniquely identify a scored image+well\n",
    "merged_df = merged_df.set_index('row_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics (or load pre-calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:13.899106Z",
     "start_time": "2021-06-02T16:09:05.030910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupancy_ratio</th>\n",
       "      <th>on_off_ratio</th>\n",
       "      <th>spot_occupancy</th>\n",
       "      <th>spot_occupancy_thresholded</th>\n",
       "      <th>image_occupancy</th>\n",
       "      <th>other_spots_occupancy</th>\n",
       "      <th>bg_occupancy</th>\n",
       "      <th>far_bg_occupancy</th>\n",
       "      <th>occupancy_vs_far_bg_ratio</th>\n",
       "      <th>in_n_spots</th>\n",
       "      <th>spot_intensity</th>\n",
       "      <th>spot_intensity_tic_norm</th>\n",
       "      <th>spot_intensity_bgr_corrected</th>\n",
       "      <th>spot_intensity_sum</th>\n",
       "      <th>spot_intensity_std</th>\n",
       "      <th>other_spot_intensity</th>\n",
       "      <th>bg_intensity</th>\n",
       "      <th>far_bg_intensity</th>\n",
       "      <th>intensity_vs_far_bg_ratio</th>\n",
       "      <th>intensity_vs_other_spots_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-15_17h57m16s_C10H26N4_+H__115</th>\n",
       "      <td>28.846154</td>\n",
       "      <td>1.636013e+07</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.846154</td>\n",
       "      <td>2</td>\n",
       "      <td>16360.128906</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>16360.128906</td>\n",
       "      <td>8.507267e+05</td>\n",
       "      <td>51789.886719</td>\n",
       "      <td>1.237866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.636013e+07</td>\n",
       "      <td>13205.733809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-15_17h57m16s_C10H26N4_+Na__115</th>\n",
       "      <td>28.846154</td>\n",
       "      <td>1.543650e+06</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.846154</td>\n",
       "      <td>4</td>\n",
       "      <td>1543.650146</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>1543.650146</td>\n",
       "      <td>8.026980e+04</td>\n",
       "      <td>4397.127930</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.543650e+06</td>\n",
       "      <td>10562.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-15_17h57m16s_C10H26N4_+K__115</th>\n",
       "      <td>5.749543</td>\n",
       "      <td>9.915556e+03</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5.749220</td>\n",
       "      <td>1</td>\n",
       "      <td>43.455296</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>43.451859</td>\n",
       "      <td>2.259675e+03</td>\n",
       "      <td>224.621765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>9.790880e+03</td>\n",
       "      <td>43455.295563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17_18h14m40s_C10H26N4_+H__115</th>\n",
       "      <td>83.555635</td>\n",
       "      <td>1.220141e+04</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>85.875339</td>\n",
       "      <td>2</td>\n",
       "      <td>28936.888672</td>\n",
       "      <td>0.023742</td>\n",
       "      <td>28936.833984</td>\n",
       "      <td>1.070665e+06</td>\n",
       "      <td>33244.863281</td>\n",
       "      <td>2.122156</td>\n",
       "      <td>2.370602</td>\n",
       "      <td>0.054245</td>\n",
       "      <td>5.237944e+05</td>\n",
       "      <td>13629.185383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17_18h14m40s_C10H26N4_+Na__115</th>\n",
       "      <td>77.545055</td>\n",
       "      <td>1.240284e+04</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>79.386183</td>\n",
       "      <td>4</td>\n",
       "      <td>1471.808350</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>1471.791626</td>\n",
       "      <td>5.445691e+04</td>\n",
       "      <td>1879.752930</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>0.117667</td>\n",
       "      <td>0.016734</td>\n",
       "      <td>8.299503e+04</td>\n",
       "      <td>8104.936776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        occupancy_ratio  on_off_ratio  \\\n",
       "row_id                                                                  \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115         28.846154  1.636013e+07   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115        28.846154  1.543650e+06   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115          5.749543  9.915556e+03   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115         83.555635  1.220141e+04   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115        77.545055  1.240284e+04   \n",
       "\n",
       "                                        spot_occupancy  \\\n",
       "row_id                                                   \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115         0.288462   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115        0.288462   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115         0.057692   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115         0.864865   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115        0.810811   \n",
       "\n",
       "                                        spot_occupancy_thresholded  \\\n",
       "row_id                                                               \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                     0.230769   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115                    0.269231   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                     0.057692   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                     0.810811   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115                    0.810811   \n",
       "\n",
       "                                        image_occupancy  \\\n",
       "row_id                                                    \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115          0.000487   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115         0.000487   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115          0.000102   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115          0.001634   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115         0.001465   \n",
       "\n",
       "                                        other_spots_occupancy  bg_occupancy  \\\n",
       "row_id                                                                        \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                0.000409      0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115               0.000409      0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                0.000000      0.000034   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                0.002304      0.000351   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115               0.001296      0.000456   \n",
       "\n",
       "                                        far_bg_occupancy  \\\n",
       "row_id                                                     \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115           0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115          0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115           0.000034   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115           0.000351   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115          0.000456   \n",
       "\n",
       "                                        occupancy_vs_far_bg_ratio  in_n_spots  \\\n",
       "row_id                                                                          \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                   28.846154           2   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115                  28.846154           4   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                    5.749220           1   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                   85.875339           2   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115                  79.386183           4   \n",
       "\n",
       "                                        spot_intensity  \\\n",
       "row_id                                                   \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115     16360.128906   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115     1543.650146   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115        43.455296   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115     28936.888672   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115     1471.808350   \n",
       "\n",
       "                                        spot_intensity_tic_norm  \\\n",
       "row_id                                                            \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                  0.005057   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115                 0.000487   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                  0.000016   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                  0.023742   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115                 0.001207   \n",
       "\n",
       "                                        spot_intensity_bgr_corrected  \\\n",
       "row_id                                                                 \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                   16360.128906   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115                   1543.650146   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                      43.451859   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                   28936.833984   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115                   1471.791626   \n",
       "\n",
       "                                        spot_intensity_sum  \\\n",
       "row_id                                                       \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115         8.507267e+05   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115        8.026980e+04   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115         2.259675e+03   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115         1.070665e+06   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115        5.445691e+04   \n",
       "\n",
       "                                        spot_intensity_std  \\\n",
       "row_id                                                       \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115         51789.886719   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115         4397.127930   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115           224.621765   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115         33244.863281   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115         1879.752930   \n",
       "\n",
       "                                        other_spot_intensity  bg_intensity  \\\n",
       "row_id                                                                       \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115               1.237866      0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115              0.145142      0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115               0.000000      0.003383   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115               2.122156      2.370602   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115              0.180594      0.117667   \n",
       "\n",
       "                                        far_bg_intensity  \\\n",
       "row_id                                                     \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115           0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115          0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115           0.003438   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115           0.054245   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115          0.016734   \n",
       "\n",
       "                                        intensity_vs_far_bg_ratio  \\\n",
       "row_id                                                              \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                1.636013e+07   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115               1.543650e+06   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                9.790880e+03   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                5.237944e+05   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115               8.299503e+04   \n",
       "\n",
       "                                        intensity_vs_other_spots_ratio  \n",
       "row_id                                                                  \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                     13205.733809  \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115                    10562.654334  \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                     43455.295563  \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                     13629.185383  \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115                     8104.936776  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate metrics\n",
    "def calc_far_bg(mask, bg):\n",
    "    \"\"\"Gets mask for background pixels that are at least 4 radii away from the spot\"\"\"\n",
    "    # 3 iterations = (1+3=)4x the spot radius\n",
    "    expanded_spot = binary_dilation(mask, crop_zeros(mask), iterations=3)\n",
    "    return bg & ~expanded_spot\n",
    "\n",
    "def occ(px):\n",
    "    \"\"\"Calculates non-zero % of the given array\"\"\"\n",
    "    return np.count_nonzero(px) / px.size\n",
    "\n",
    "\n",
    "metrics = []\n",
    "for row in merged_df.itertuples():\n",
    "    grid = grids[row.dataset_id]\n",
    "    \n",
    "    mask = grid == row.well\n",
    "    bg = grid == 0\n",
    "    far_bg = calc_far_bg(mask, bg)\n",
    "        \n",
    "    in_mask = row.image[mask]\n",
    "    in_mask_tic_norm = row.tic_norm_image[mask]\n",
    "    in_bg = row.image[bg]\n",
    "    in_far_bg = row.image[far_bg]\n",
    "    in_other_spots = row.image[~bg & ~mask]\n",
    "    \n",
    "    # Calculate threshold (0.01 * 99th percentile) \n",
    "    # (note the image is already hotspot-removed, so the max is the 99th percentile)\n",
    "    threshold = np.max(row.image) * 0.01\n",
    "\n",
    "    metrics.append({\n",
    "        'row_id': row[0],   # with .itertuples(), item[0] is the index\n",
    "        # Original metrics\n",
    "        # NOTE: The constant in the denominator of `on_off_ratio` was changed to\n",
    "        # 0.001 as it seemed to produce slightly better results\n",
    "        'occupancy_ratio': (occ(in_mask) * 100) / (occ(in_bg) * 100 + 1),\n",
    "        'on_off_ratio': (np.mean(in_mask)) / (np.mean(in_bg) + 0.001),\n",
    "        \n",
    "        # Single-spot occupancy %\n",
    "        'spot_occupancy': occ(in_mask),\n",
    "        'spot_occupancy_thresholded': occ(in_mask > threshold),\n",
    "        # Other occupancy metrics\n",
    "        'image_occupancy': occ(row.image),\n",
    "        'other_spots_occupancy': occ(in_other_spots),\n",
    "        'bg_occupancy': occ(in_bg),\n",
    "        'far_bg_occupancy': occ(in_bg),\n",
    "        'occupancy_vs_far_bg_ratio' : (occ(in_mask) * 100) / (occ(in_far_bg) * 100 + 1),\n",
    "        \n",
    "        # How many spots have a non-zero pixel\n",
    "        'in_n_spots': len(np.unique(grid[(grid != 0) & (row.image > threshold)])),\n",
    "        \n",
    "        # Intensity ratios\n",
    "        'spot_intensity' : np.mean(in_mask),\n",
    "        'spot_intensity_tic_norm': np.mean(in_mask_tic_norm),\n",
    "        'spot_intensity_bgr_corrected' : np.mean(in_mask) - np.mean(in_far_bg),\n",
    "        'spot_intensity_sum' : np.sum(in_mask),\n",
    "        'spot_intensity_std' : np.std(in_mask),\n",
    "        'other_spot_intensity': np.mean(in_other_spots),\n",
    "        'bg_intensity' : np.mean(in_bg),\n",
    "        'far_bg_intensity' : np.mean(in_far_bg),\n",
    "        #Intensity ratios\n",
    "        'intensity_vs_far_bg_ratio': np.mean(in_mask) / (np.mean(in_far_bg) + 0.001),\n",
    "        'intensity_vs_other_spots_ratio': np.mean(in_mask) / (np.mean(in_other_spots) + 0.001),\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).set_index('row_id')\n",
    "metrics_df.to_csv(p_metrics)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Or import pre-calculated metrics\n",
    "metrics_df = pd.read_csv(p_metrics, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupancy_ratio</th>\n",
       "      <th>on_off_ratio</th>\n",
       "      <th>spot_occupancy</th>\n",
       "      <th>spot_occupancy_thresholded</th>\n",
       "      <th>image_occupancy</th>\n",
       "      <th>other_spots_occupancy</th>\n",
       "      <th>bg_occupancy</th>\n",
       "      <th>far_bg_occupancy</th>\n",
       "      <th>occupancy_vs_far_bg_ratio</th>\n",
       "      <th>in_n_spots</th>\n",
       "      <th>...</th>\n",
       "      <th>spot_intensity_tic_norm</th>\n",
       "      <th>spot_intensity_bgr_corrected</th>\n",
       "      <th>spot_intensity_sum</th>\n",
       "      <th>spot_intensity_std</th>\n",
       "      <th>other_spot_intensity</th>\n",
       "      <th>bg_intensity</th>\n",
       "      <th>far_bg_intensity</th>\n",
       "      <th>intensity_vs_far_bg_ratio</th>\n",
       "      <th>intensity_vs_other_spots_ratio</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-15_17h57m16s_C10H26N4_+H__115</th>\n",
       "      <td>28.846154</td>\n",
       "      <td>1.636013e+07</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.846154</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>16360.128906</td>\n",
       "      <td>8.507267e+05</td>\n",
       "      <td>51789.886719</td>\n",
       "      <td>1.237866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.636013e+07</td>\n",
       "      <td>13205.733809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-15_17h57m16s_C10H26N4_+Na__115</th>\n",
       "      <td>28.846154</td>\n",
       "      <td>1.543650e+06</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.846154</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>1543.650146</td>\n",
       "      <td>8.026980e+04</td>\n",
       "      <td>4397.127930</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.543650e+06</td>\n",
       "      <td>10562.654334</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-15_17h57m16s_C10H26N4_+K__115</th>\n",
       "      <td>5.749543</td>\n",
       "      <td>9.915556e+03</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5.749220</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>43.451859</td>\n",
       "      <td>2.259675e+03</td>\n",
       "      <td>224.621765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>9.790880e+03</td>\n",
       "      <td>43455.295563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17_18h14m40s_C10H26N4_+H__115</th>\n",
       "      <td>83.555635</td>\n",
       "      <td>1.220141e+04</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>85.875339</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023742</td>\n",
       "      <td>28936.833984</td>\n",
       "      <td>1.070665e+06</td>\n",
       "      <td>33244.863281</td>\n",
       "      <td>2.122156</td>\n",
       "      <td>2.370602</td>\n",
       "      <td>0.054245</td>\n",
       "      <td>5.237944e+05</td>\n",
       "      <td>13629.185383</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17_18h14m40s_C10H26N4_+Na__115</th>\n",
       "      <td>77.545055</td>\n",
       "      <td>1.240284e+04</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>79.386183</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>1471.791626</td>\n",
       "      <td>5.445691e+04</td>\n",
       "      <td>1879.752930</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>0.117667</td>\n",
       "      <td>0.016734</td>\n",
       "      <td>8.299503e+04</td>\n",
       "      <td>8104.936776</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        occupancy_ratio  on_off_ratio  \\\n",
       "row_id                                                                  \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115         28.846154  1.636013e+07   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115        28.846154  1.543650e+06   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115          5.749543  9.915556e+03   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115         83.555635  1.220141e+04   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115        77.545055  1.240284e+04   \n",
       "\n",
       "                                        spot_occupancy  \\\n",
       "row_id                                                   \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115         0.288462   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115        0.288462   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115         0.057692   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115         0.864865   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115        0.810811   \n",
       "\n",
       "                                        spot_occupancy_thresholded  \\\n",
       "row_id                                                               \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                     0.230769   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115                    0.269231   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                     0.057692   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                     0.810811   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115                    0.810811   \n",
       "\n",
       "                                        image_occupancy  \\\n",
       "row_id                                                    \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115          0.000487   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115         0.000487   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115          0.000102   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115          0.001634   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115         0.001465   \n",
       "\n",
       "                                        other_spots_occupancy  bg_occupancy  \\\n",
       "row_id                                                                        \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                0.000409      0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115               0.000409      0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                0.000000      0.000034   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                0.002304      0.000351   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115               0.001296      0.000456   \n",
       "\n",
       "                                        far_bg_occupancy  \\\n",
       "row_id                                                     \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115           0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115          0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115           0.000034   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115           0.000351   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115          0.000456   \n",
       "\n",
       "                                        occupancy_vs_far_bg_ratio  in_n_spots  \\\n",
       "row_id                                                                          \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                   28.846154           2   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115                  28.846154           4   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                    5.749220           1   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                   85.875339           2   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115                  79.386183           4   \n",
       "\n",
       "                                        ...  spot_intensity_tic_norm  \\\n",
       "row_id                                  ...                            \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115   ...                 0.005057   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115  ...                 0.000487   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115   ...                 0.000016   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115   ...                 0.023742   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115  ...                 0.001207   \n",
       "\n",
       "                                        spot_intensity_bgr_corrected  \\\n",
       "row_id                                                                 \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                   16360.128906   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115                   1543.650146   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                      43.451859   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                   28936.833984   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115                   1471.791626   \n",
       "\n",
       "                                        spot_intensity_sum  \\\n",
       "row_id                                                       \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115         8.507267e+05   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115        8.026980e+04   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115         2.259675e+03   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115         1.070665e+06   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115        5.445691e+04   \n",
       "\n",
       "                                        spot_intensity_std  \\\n",
       "row_id                                                       \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115         51789.886719   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115         4397.127930   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115           224.621765   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115         33244.863281   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115         1879.752930   \n",
       "\n",
       "                                        other_spot_intensity  bg_intensity  \\\n",
       "row_id                                                                       \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115               1.237866      0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115              0.145142      0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115               0.000000      0.003383   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115               2.122156      2.370602   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115              0.180594      0.117667   \n",
       "\n",
       "                                        far_bg_intensity  \\\n",
       "row_id                                                     \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115           0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115          0.000000   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115           0.003438   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115           0.054245   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115          0.016734   \n",
       "\n",
       "                                        intensity_vs_far_bg_ratio  \\\n",
       "row_id                                                              \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                1.636013e+07   \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115               1.543650e+06   \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                9.790880e+03   \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                5.237944e+05   \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115               8.299503e+04   \n",
       "\n",
       "                                        intensity_vs_other_spots_ratio  score  \n",
       "row_id                                                                         \n",
       "2021-02-15_17h57m16s_C10H26N4_+H__115                     13205.733809    NaN  \n",
       "2021-02-15_17h57m16s_C10H26N4_+Na__115                    10562.654334    NaN  \n",
       "2021-02-15_17h57m16s_C10H26N4_+K__115                     43455.295563    NaN  \n",
       "2021-02-17_18h14m40s_C10H26N4_+H__115                     13629.185383    1.0  \n",
       "2021-02-17_18h14m40s_C10H26N4_+Na__115                     8104.936776    1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = metrics_df.merge(merged_df[['score']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "# metrics_df.drop(columns = ['occupancy_ratio', 'on_off_ratio', \n",
    "#        'other_spots_occupancy', 'bg_occupancy', 'far_bg_occupancy', \n",
    "#         'in_n_spots', 'intensity_vs_other_spots_ratio', 'spot_intensity'\n",
    "#        ], inplace=True)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models\n",
    "\n",
    "This section uses the calculated metrics and labeled data to train a set of models \n",
    "and find which features are best for predicting the labels. \n",
    "It uses two strategies for evaluation:\n",
    "\n",
    "* Hold-out validation - this splits the labeled data into 80% for training, 20% for testing\n",
    "* Cross-Validation - this uses the full labeled data, but trains 5 different models, each\n",
    "    with a different combinations of inputs in the 80% training set, so that each input \n",
    "    can be tested by a model that didn't use that input as part of the training.\n",
    "    This approach reports a much more numerically stable accuracy value it can use \n",
    "    the full input set for evaluation.\n",
    "    However, it shouldn't be used for fine-tuning the model hyperparameters \n",
    "    (the input variables when constructing the model), as this can lead to overfitting.\n",
    "    \n",
    "   \n",
    "The output is a DataFrame `eval_results_df` that shows for each model/# of features:\n",
    "* Which combination of features worked best\n",
    "* The accuracy/F1 scores\n",
    "* The # of false positives & false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:09:16.020437Z",
     "start_time": "2021-06-02T16:09:15.995812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare input data\n",
    "input_df = metrics_df[~metrics_df.score.isna()]  # Exclude unlabeled rows\n",
    "input_df = input_df.sample(frac=1.0)  # Shuffle rows\n",
    "X = input_df.drop(columns=['score'])\n",
    "y = input_df.score.astype('i').values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:14:59.114845Z",
     "start_time": "2021-06-02T16:09:16.668321Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models to try\n",
    "models_to_eval = [\n",
    "    CatBoostClassifier(verbose=False),\n",
    "#     LinearSVC(class_weight='balanced'),\n",
    "#     DecisionTreeClassifier(max_depth=3),\n",
    "#     BaggingClassifier(LinearSVC(), n_estimators=3, bootstrap_features=True),\n",
    "]\n",
    "max_features_to_consider = 4\n",
    "\n",
    "eval_results = []\n",
    "\n",
    "for model in models_to_eval:\n",
    "    model_name = str(model)\n",
    "    for n_features in range(1, max_features_to_consider + 1):\n",
    "        print(model_name, n_features)\n",
    "        # SequentialFeatureSelector finds the set of N features that give the best scores\n",
    "        sfs = SequentialFeatureSelector(model, n_features_to_select=n_features, n_jobs=-1)\n",
    "        sfs.fit(X_train, y_train)\n",
    "        best_features = X.columns[sfs.support_]\n",
    "        \n",
    "        # Evaluate using cross-validation\n",
    "        X_subset = X[best_features].values\n",
    "        fpos_idxs, fneg_idxs = get_mispredictions(model, X_subset, y)\n",
    "        # Use a repeating cross-validator so that results are averaged over ~50 runs\n",
    "        cv = RepeatedStratifiedKFold()\n",
    "        cv_scores = cross_validate(model, X_subset, y, cv=cv, scoring=['accuracy','f1'])\n",
    "        cv_accuracy = np.mean(cv_scores['test_accuracy'])\n",
    "        cv_f1 = np.mean(cv_scores['test_f1'])\n",
    "        \n",
    "        # Evaluate using hold-out validation\n",
    "        trained_subset_model = clone(model).fit(X_train[best_features].values, y_train)\n",
    "        holdout_accuracy = trained_subset_model.score(X_test[best_features].values, y_test)\n",
    "        holdout_f1 = f1_score(y_test, trained_subset_model.predict(X_test[best_features].values))\n",
    "        \n",
    "        eval_results.append({\n",
    "            'model': model_name,\n",
    "            'n_features': n_features,\n",
    "            'features': ', '.join(best_features),\n",
    "            'cv_accuracy': cv_accuracy,\n",
    "            'cv_f1': cv_f1,\n",
    "            'holdout_accuracy': holdout_accuracy,\n",
    "            'holdout_f1': holdout_f1,\n",
    "            'n_fpos': len(fpos_idxs),\n",
    "            'n_fneg': len(fneg_idxs),\n",
    "            # Uncomment to include the idxs of false positives/negatives to see which\n",
    "            # inputs are repeatedly mispredicted regardless of the model\n",
    "            # 'fpos_idxs': fpos_idxs,\n",
    "            # 'fneg_idxs': fneg_idxs,\n",
    "        })\n",
    "        \n",
    "eval_results_df = pd.DataFrame(eval_results)\n",
    "\n",
    "eval_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:22:29.917816Z",
     "start_time": "2021-06-02T16:22:29.830719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show behavior of accuracy as number of features increases\n",
    "sns.lineplot(data=eval_results_df, x='n_features', y='cv_accuracy', hue='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_results_df.features.iloc[0])\n",
    "print(eval_results_df.features.iloc[1])\n",
    "print(eval_results_df.features.iloc[2])\n",
    "print(eval_results_df.features.iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results for a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:54:58.014519Z",
     "start_time": "2021-06-02T16:54:57.991621Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(verbose=False)\n",
    "features = ['spot_intensity_tic_norm', 'spot_occupancy', 'occupancy_vs_far_bg_ratio', 'intensity_vs_far_bg_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:29.785376Z",
     "start_time": "2021-06-02T16:58:26.677693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model on labeled data\n",
    "train_df = metrics_df[~metrics_df.score.isna()]  # Exclude unlabeled rows\n",
    "train_df = input_df.sample(frac=1.0)  # Shuffle rows\n",
    "X_df = train_df.drop(columns=['score'])[features]\n",
    "y = train_df.score.astype('i').values\n",
    "trained_model = clone(model).fit(X_df.values, y)\n",
    "\n",
    "# Make predictions for unlabeled data\n",
    "unlabeled_df = metrics_df[metrics_df.score.isna()][features]\n",
    "unlabeled_predictions_df = pd.DataFrame({\n",
    "    'pred_val': trained_model.predict_proba(unlabeled_df.values)[:, 1]\n",
    "}, index=unlabeled_df.index)\n",
    "\n",
    "# Make cross-validated predictions for labeled data\n",
    "labeled_predictions_df = pd.DataFrame({\n",
    "    'pred_val': cross_val_predict(model, X_df.values, y, method='predict_proba')[:, 1]\n",
    "}, index=X_df.index)\n",
    "\n",
    "# Combine predictions\n",
    "predictions_df = pd.concat([unlabeled_predictions_df, labeled_predictions_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Load an existing model\n",
    "Uses a saved model from the last step of this file\n",
    "\n",
    "NOTE: This approach doesn't use cross-validated predictions for the labelled training data,\n",
    "so it shouldn't be used for analyzing the model or refining the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T15:54:16.477074Z",
     "start_time": "2021-06-02T15:53:05.276Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_model(p_eval / 'model.json', format='json')\n",
    "\n",
    "# # Make predictions for all data\n",
    "# predictions_df = pd.DataFrame({\n",
    "#     'pred_val': model.predict_proba(metrics_df[features].values)[:, 1]\n",
    "# }, index=metrics_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both options: Assign labels to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:47.130742Z",
     "start_time": "2021-06-02T16:58:47.104805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make combined DF\n",
    "output_df = merged_df.join(metrics_df.drop(columns='score')).join(predictions_df)\n",
    "\n",
    "# Add two-state and three-state classes\n",
    "output_df['pred_twostate'] = np.where(output_df.pred_val < 0.5, 0, 1)\n",
    "unsure_range = [0.2, 0.8] # Lowest & highest values to include in the \"unsure\" class\n",
    "# This assigns 0 = negative, 1 = unsure, 2 = positive\n",
    "output_df['pred_threestate'] = np.digitize(output_df.pred_val, unsure_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write predictions CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:58:48.369446Z",
     "start_time": "2021-06-02T16:58:48.294036Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_df = output_df.drop(columns=['image', 'filename']) # Skip unwanted columns\n",
    "csv_df.to_csv(p_predictions)\n",
    "\n",
    "for dataset_id, results_df in csv_df.groupby('dataset_id'):\n",
    "    output_path = p_eval / f'{dataset_id}_predictions.csv'\n",
    "    results_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write image files into false positives, false negatives, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-02T16:58:53.453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean output directories\n",
    "for output_path in [\n",
    "    p_eval_fpos, p_eval_fneg, p_eval_tpos, p_eval_tneg, p_eval_upos, p_eval_uneg, \n",
    "    p_tri_pos, p_tri_unk, p_tri_neg\n",
    "]:\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    for f in output_path.glob('*.png'):\n",
    "        f.unlink()  # Delete existing files\n",
    "\n",
    "# Write images with two-state classification\n",
    "for row in output_df.itertuples():\n",
    "    mask = grids[row.dataset_id] == row.well\n",
    "    \n",
    "    # Figure out which directory to use\n",
    "    if row.score == 0:\n",
    "        twostate_path = [p_eval_tneg, p_eval_fpos][row.pred_twostate]\n",
    "    elif row.score == 1:\n",
    "        twostate_path = [p_eval_fneg, p_eval_tpos][row.pred_twostate]\n",
    "    else:\n",
    "        twostate_path = [p_eval_uneg, p_eval_upos][row.pred_twostate]\n",
    "    \n",
    "    save_image_with_mask(row.image, mask, twostate_path / row.filename)\n",
    "    \n",
    "# Write images with three-state classification\n",
    "for row in output_df.itertuples():\n",
    "    mask = grids[row.dataset_id] == row.well\n",
    "    \n",
    "    threestate_path = [p_tri_neg, p_tri_unk, p_tri_pos][row.pred_threestate]\n",
    "    \n",
    "    save_image_with_mask(row.image, mask, threestate_path / row.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained model\n",
    "\n",
    "Note: This JSON export only works for CatBoost. \n",
    "scikit-learn models don't have a standardized export format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-02T16:59:12.221Z"
    }
   },
   "outputs": [],
   "source": [
    "trained_model.save_model(p_model, format='json', pool=Pool(X_df.values, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
